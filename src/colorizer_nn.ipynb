{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import packages and device selection",
   "id": "b313fc0badf68a12"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.functional.image import structural_similarity_index_measure\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SIZE = 224\n",
    "seed = 42\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed) # if using CPU\n",
    "torch.cuda.manual_seed(seed) # if using single-GPU\n",
    "torch.cuda.manual_seed_all(seed) # if using multi-GPU\n",
    "torch.backends.cudnn.deterministic = True # deterministic mode\n",
    "torch.backends.cudnn.benchmark = False # disable auto-tuner to find the best algorithm to use for your hardware\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow TensorFloat-32 on matmul operations\n",
    "torch.backends.cudnn.allow_tf32  = True # allow TensorFloat-32 on convolution operations"
   ],
   "id": "2e23ac1ba4189527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Using device: \", device)",
   "id": "59ca34fe3c6ae5d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Loading and Preprocessing",
   "id": "fbfc50c6b8689727"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### This is used only to visualize some samples from the dataset",
   "id": "6c78250abb31e2a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sort_files(folder):\n",
    "    convert_func = lambda x: int(x) if x.isdigit() else x.lower()\n",
    "    key_func = lambda x: [convert_func(c) for c in re.split('([0-9]+)', x)]\n",
    "    return sorted(folder, key=key_func)\n",
    "\n",
    "input_L = []\n",
    "target_ab = []\n",
    "path = '../data/color'\n",
    "folder = os.listdir(path)\n",
    "folder = sort_files(folder)\n",
    "for file in tqdm(folder, desc='Loading color images'):\n",
    "    img = cv2.imread(os.path.join(path, file), 1)\n",
    "    img = img.astype(np.float32) / 255.0 # [0..1]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    L = img[:, :, 0:1] # (H, W, 1) [0..100]\n",
    "    ab = img[:, :, 1:3] # (H, W, 2) [-128..127]\n",
    "    input_L.append(L)\n",
    "    target_ab.append(ab)\n",
    "input_L = np.array(input_L) # (N, H, W, 1)\n",
    "target_ab = np.array(target_ab) # (N, H, W, 2\n",
    "\n",
    "# def sort_files(folder):\n",
    "#     convert_func = lambda x: int(x) if x.isdigit() else x.lower()\n",
    "#     key_func = lambda x: [convert_func(c) for c in re.split('([0-9]+)', x)]\n",
    "#     return sorted(folder, key=key_func)\n",
    "#\n",
    "# input_L = []\n",
    "# target_ab = []\n",
    "# path = '../data/color'\n",
    "# folder = os.listdir(path)\n",
    "# folder = sort_files(folder)"
   ],
   "id": "71ceb81e212e2ca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(input_L.shape, target_ab.shape)",
   "id": "3f03936b33e6388b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Display some samples",
   "id": "e01565f8500bee4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _ in range(5):\n",
    "    idx = np.random.randint(0, len(input_L) - 1)\n",
    "    color_img = np.concatenate([input_L[idx] / 100 * 255, target_ab[idx] + 128], axis=2).clip(0, 255).astype(np.uint8)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('RGB Color Image', fontsize=20)\n",
    "    plt.imshow(np.clip(cv2.cvtColor(color_img, cv2.COLOR_LAB2RGB), 0, 255))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Lab Color Image', fontsize=20)\n",
    "    plt.imshow(color_img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Grayscale Image ', fontsize=20)\n",
    "    plt.imshow((input_L[idx] / 100 * 255).astype(np.uint8).squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "id": "8c4b97681d3cd431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Split into training and test data",
   "id": "e78f0f02e2584c76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# del input_L, target_ab\n",
    "# all_filepaths = np.array([os.path.join(path, file) for file in folder])\n",
    "# train_data, test_data = train_test_split(all_filepaths, test_size=0.3, random_state=seed)\n",
    "# val_data, test_data = train_test_split(test_data, test_size=0.3, random_state=seed)"
   ],
   "id": "ce77287da9ce5aa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# print(train_data.shape, val_data.shape, test_data.shape)",
   "id": "f186b3490baaee72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can use the entire dataset, instead of the file path, as it is small enough to fit in memory",
   "id": "5d271a4d5931e1a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_L = (torch.from_numpy(input_L) / 100.0).permute(0, 3, 1, 2) # (N, 1, H, W) [0..1]\n",
    "target_ab = torch.from_numpy(target_ab).permute(0, 3, 1, 2) # (N, 2, H, W) [-128..127]\n",
    "L_train, L_test, ab_train, ab_test = train_test_split(input_L, target_ab, test_size=0.2, random_state=seed)\n",
    "L_val, L_test, ab_val, ab_test = train_test_split(L_test, ab_test, test_size=0.2, random_state=seed)"
   ],
   "id": "dc9ee95b401f03a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(L_train.shape, ab_train.shape)\n",
    "print(L_val.shape, ab_val.shape)\n",
    "print(L_test.shape, ab_test.shape)"
   ],
   "id": "852c84cd362149e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "L_mean = torch.mean(L_train, dim=[0, 2, 3])\n",
    "L_std = torch.std(L_train, dim=[0, 2, 3])"
   ],
   "id": "3cb7f69c462b8201",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(L_mean, L_std)",
   "id": "1e316003a8a3d88a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, L_data, ab_data, L_transform=None):\n",
    "        self.L_data = L_transform(L_data) if L_transform else L_data\n",
    "        self.ab_data = ab_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.L_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.L_data[idx], self.ab_data[idx]\n",
    "\n",
    "# class MyDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, filepaths, lut, L_transform=None):\n",
    "#         self.filepaths = filepaths\n",
    "#         self.lut = lut.cpu()\n",
    "#         self.L_transform = L_transform\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.filepaths)\n",
    "#\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.filepaths[idx]\n",
    "#         img = cv2.imread(img_path, 1)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "#         img = cv2.resize(img, (SIZE, SIZE))\n",
    "#         L = (img[:, :, 0:1].astype(np.float32) / 255.0).transpose(2, 0, 1) # (1, H, W) [0..1]\n",
    "#         ab = (img[:, :, 1:3].astype(np.uint8)).transpose(2, 0, 1) # (2, H, W) [0..255]\n",
    "#         L_data = torch.from_numpy(L)\n",
    "#         ab_data = torch.from_numpy(ab).long()\n",
    "#         if self.L_transform:\n",
    "#             L_data = self.L_transform(L_data)\n",
    "#         with torch.no_grad():\n",
    "#             a = ab_data[0, :, :]\n",
    "#             b = ab_data[1, :, :]\n",
    "#             idx = a * 256 + b\n",
    "#             label = self.lut[idx]\n",
    "#         return L_data, label"
   ],
   "id": "d8b78562cbcec18f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CUDAPrefetcher:\n",
    "    def __init__(self, loader):\n",
    "        self.loader = iter(loader)\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.next_L = None\n",
    "        self.next_ab = None\n",
    "        self._preload()\n",
    "\n",
    "    def _preload(self):\n",
    "        try:\n",
    "            self.next_L, self.next_ab = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_L = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_L = self.next_L.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "            self.next_ab = self.next_ab.to(device, non_blocking=True)\n",
    "\n",
    "    def next(self):\n",
    "        torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        L, ab = self.next_L, self.next_ab\n",
    "        self._preload()\n",
    "        return L, ab\n",
    "\n",
    "# class CUDAPrefetcher:\n",
    "#     def __init__(self, loader):\n",
    "#         self.loader = iter(loader)\n",
    "#         self.stream = torch.cuda.Stream()\n",
    "#         self.next_L = None\n",
    "#         self.next_labels = None\n",
    "#         self._preload()\n",
    "#\n",
    "#     def _preload(self):\n",
    "#         try:\n",
    "#             self.next_L, self.next_labels = next(self.loader)\n",
    "#         except StopIteration:\n",
    "#             self.next_L = None\n",
    "#             return\n",
    "#         with torch.cuda.stream(self.stream):\n",
    "#             self.next_L = self.next_L.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "#             self.next_labels = self.next_labels.to(device, non_blocking=True)\n",
    "#\n",
    "#     def next(self):\n",
    "#         torch.cuda.current_stream().wait_stream(self.stream)\n",
    "#         L, labels = self.next_L, self.next_labels\n",
    "#         self._preload()\n",
    "#         return L, labels"
   ],
   "id": "d25b98ac3e54d495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# cluster_path = '../data/pts_in_hull.npy'\n",
    "# assert os.path.exists(cluster_path), \"Download pts_in_hull.npy and place next to this script\"\n",
    "# cluster_centers = torch.from_numpy(np.load(cluster_path)).float() # (313, 2) [-128..127]\n",
    "# cc_l2 = (cluster_centers ** 2).sum(dim=1) # (313,)\n",
    "# lut_coords  = (((torch.stack(torch.meshgrid(torch.arange(256), torch.arange(256), indexing='xy'), dim=-1).float()) - 128.0)\n",
    "#                .reshape(-1, 2)) # (65536, 2) [-128..127]\n",
    "#\n",
    "# def compute_dist(tensor):\n",
    "#     dists = ((tensor ** 2).sum(dim=1, keepdim=True) # (B*H*W, 1)\n",
    "#              + cc_l2.reshape(1, -1) # (1, 313)\n",
    "#              - 2 * torch.matmul(tensor, cluster_centers.t())) # (B*H*W, 313)\n",
    "#     return dists\n",
    "#\n",
    "# dists = compute_dist(lut_coords)\n",
    "# del lut_coords\n",
    "# # lut = torch.argmin(dists, dim=1).long() # (65536,) [0..312] LUT for mapping (a, b) to cluster index\n",
    "# soft_lut_probs = torch.softmax(-dists, dim=1)  # shape: (65536, 313)\n",
    "# lut = torch.argmax(soft_lut_probs, dim=1).long()  # shape: (65536,)\n",
    "# del dists"
   ],
   "id": "a3104fa964b7baf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# temp_dataset = MyDataset(train_data, lut)\n",
    "# temp_loader = DataLoader(temp_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "# L_pixel_count, L_sum, L_sum_sq = 0, 0.0, 0.0\n",
    "# ab_pixel_count, ab_sum, ab_sum_sq = 0, 0.0, 0.0\n",
    "# for l, ab in tqdm(temp_loader, desc='Computing L and ab channel mean and std'):\n",
    "#     l = l.float()\n",
    "#     ab = ab.float()\n",
    "#     L_sum += torch.sum(l)\n",
    "#     L_sum_sq += torch.sum(l ** 2)\n",
    "#     L_pixel_count += l.numel()\n",
    "#     ab_sum += torch.sum(ab)\n",
    "#     ab_sum_sq += torch.sum(ab ** 2)\n",
    "#     ab_pixel_count += ab.numel()\n",
    "# L_mean = (L_sum / L_pixel_count).item()\n",
    "# L_std = torch.sqrt((L_sum_sq / L_pixel_count) - (L_mean ** 2)).item()\n",
    "# ab_mean = (ab_sum / ab_pixel_count).item()\n",
    "# ab_std = torch.sqrt((ab_sum_sq / ab_pixel_count) - (ab_mean ** 2)).item()\n",
    "# del temp_dataset, temp_loader, l, ab, L_sum, L_sum_sq, L_pixel_count, ab_sum, ab_sum_sq, ab_pixel_count"
   ],
   "id": "367d9520c93c93ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(L_mean, L_std)\n",
    "# print(ab_mean, ab_std)"
   ],
   "id": "6e0d7bae465b85f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainset = MyDataset(L_train, ab_train, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "valset = MyDataset(L_val, ab_val, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "testset = MyDataset(L_test, ab_test, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "del L_train, ab_train, L_val, ab_val, L_test, ab_test"
   ],
   "id": "ba8dda1b447c7b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training pipeline",
   "id": "5b1cc3045bc3a88a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Early stopping used to stop training if model begins to overfit",
   "id": "6b19cc4864aa482e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_checkpoint(model, name='checkpoint'):\n",
    "    torch.save(model.state_dict(), f\"../models/{name}.pth\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.05):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = np.Inf\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, net):\n",
    "        if self.best_score > val_loss:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "            save_checkpoint(net)\n",
    "        elif self.best_score + self.delta < val_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ],
   "id": "9c573fa9f9a004e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check VGG19 architecture to select layers for perceptual loss",
   "id": "e967f16d07a9f8d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features)\n",
    "ext_layer = 17  # extract features up to this layer (0-indexed)"
   ],
   "id": "9ed18dbc8495e450",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, layers=(16,)):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features\n",
    "        self.slices = nn.ModuleList()\n",
    "        prev = 0\n",
    "        for i in sorted(layers):\n",
    "            slice = nn.Sequential(*list(vgg.children())[prev:i + 1])\n",
    "            self.slices.append(slice.eval())\n",
    "            prev = i + 1\n",
    "        for slice in self.slices:\n",
    "            for p in slice.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
    "        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
    "        self.loss_fn = nn.L1Loss()\n",
    "\n",
    "    def _lab_to_rgb(self, L, ab):\n",
    "        L = L * 100.0\n",
    "        lab = torch.cat([L, ab], dim=1) # (B, 3, H, W)\n",
    "        Y = (lab[:, 0:1, :, :] + 16.) / 116.\n",
    "        X = lab[:, 1:2, :, :] / 500. + Y\n",
    "        Z = Y - lab[:, 2:3, :, :] / 200.\n",
    "        Y = torch.where(Y > 0.008856, Y ** 3, (Y - 16. / 116.) / 7.787)\n",
    "        X = torch.where(X > 0.008856, X ** 3, (X - 16. / 116.) / 7.787)\n",
    "        Z = torch.where(Z > 0.008856, Z ** 3, (Z - 16. / 116.) / 7.787)\n",
    "        xyz = torch.cat([X, Y, Z], dim=1)\n",
    "        xyz[:, 0:1, :, :] = xyz[:, 0:1, :, :] * 0.95047\n",
    "        xyz[:, 2:3, :, :] = xyz[:, 2:3, :, :] * 1.08883\n",
    "        rgb = torch.zeros_like(xyz)\n",
    "        rgb[:, 0:1, :, :] = (3.2404542 * xyz[:, 0:1, :, :] - 1.5371385 *\n",
    "                             xyz[:, 1:2, :, :] - 0.4985314 * xyz[:, 2:3, :, :])\n",
    "        rgb[:, 1:2, :, :] = (-0.9692660 * xyz[:, 0:1, :, :] + 1.8760108 *\n",
    "                             xyz[:, 1:2, :, :] + 0.0415560 * xyz[:, 2:3, :, :])\n",
    "        rgb[:, 2:3, :, :] = (0.0556434 * xyz[:, 0:1, :, :] - 0.2040259 *\n",
    "                             xyz[:, 1:2, :, :] + 1.0572252 * xyz[:, 2:3, :, :])\n",
    "        rgb = torch.where(rgb > 0.0031308, 1.055 * (rgb.pow(1.0 / 2.4)) - 0.055, 12.92 * rgb)\n",
    "        return torch.clamp(rgb, 0.0, 1.0)\n",
    "\n",
    "    def forward(self, L, ab_pred, ab_target):\n",
    "        pred_rgb = (self._lab_to_rgb(L, ab_pred) - self.mean) / self.std\n",
    "        target_rgb = (self._lab_to_rgb(L, ab_target) - self.mean) / self.std\n",
    "        loss = 0.0\n",
    "        for slice in self.slices:\n",
    "            x = slice(pred_rgb)\n",
    "            y = slice(target_rgb)\n",
    "            loss += self.loss_fn(x, y)\n",
    "        return loss / len(self.slices)\n",
    "\n",
    "def compute_pcc_components(pred, targets):\n",
    "    pred_flat = pred.reshape(pred.size(0), -1)\n",
    "    target_flat = targets.reshape(targets.size(0), -1)\n",
    "    vx = pred_flat - pred_flat.mean(dim=1, keepdim=True)\n",
    "    vy = target_flat - target_flat.mean(dim=1, keepdim=True)\n",
    "    numerator = (vx * vy).sum(dim=1) # covariance\n",
    "    denominator1 = (vx ** 2).sum(dim=1)\n",
    "    denominator2 = (vy ** 2).sum(dim=1)\n",
    "    return numerator, denominator1, denominator2\n",
    "\n",
    "def fit(net, trainloader, optimizer, scaler, loss_pixel_fn, loss_vgg_fn, gamma, beta):\n",
    "    net.train()\n",
    "    total_loss, total_sse, total_psnr, total_ssim, total_pcc_num, total_pcc_den1, total_pcc_den2, pixels, count = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0\n",
    "    prefetcher = CUDAPrefetcher(trainloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    while inputs is not None:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out, mu, logvar = net(inputs)\n",
    "            out = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "            loss_rec = loss_pixel_fn(out, targets) + gamma * loss_vgg_fn(inputs, out, targets)\n",
    "            loss_kld = -0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim=1).mean()\n",
    "            loss = loss_rec + beta * loss_kld\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), 2)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        with torch.no_grad():\n",
    "            total_loss += loss_rec.item()\n",
    "            count += 1\n",
    "            sse = nn.MSELoss(reduction='sum')(out, targets)\n",
    "            pixels += targets.numel()\n",
    "            pcc_num, pcc_den1, pcc_den2 = compute_pcc_components(out, targets)\n",
    "            total_sse += sse.item()\n",
    "            total_ssim += structural_similarity_index_measure(out, targets).item()\n",
    "            total_pcc_num += pcc_num.sum().item()\n",
    "            total_pcc_den1 += pcc_den1.sum().item()\n",
    "            total_pcc_den2 += pcc_den2.sum().item()\n",
    "        inputs, targets = prefetcher.next()\n",
    "    avg_mse = total_sse / pixels\n",
    "    avg_rmse = avg_mse ** 0.5\n",
    "    return (total_loss / count, avg_rmse, 10 * np.log10(255.0 ** 2 / avg_rmse), total_ssim / count,\n",
    "            (total_pcc_num / ((total_pcc_den1 * total_pcc_den2) ** 0.5) + 1e-6))\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict(net, valloader, loss_pixel_fn, loss_vgg_fn, gamma):\n",
    "    net.eval()\n",
    "    total_loss, total_sse, total_psnr, total_ssim, total_pcc_num, total_pcc_den1, total_pcc_den2, pixels, count = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0\n",
    "    prefetcher = CUDAPrefetcher(valloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    while inputs is not None:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out, mu, logvar = net(inputs)\n",
    "            out = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "            loss_rec = loss_pixel_fn(out, targets) + gamma * loss_vgg_fn(inputs, out, targets)\n",
    "        total_loss += loss_rec.item()\n",
    "        count += 1\n",
    "        sse = nn.MSELoss(reduction='sum')(out, targets)\n",
    "        pixels += targets.numel()\n",
    "        pcc_num, pcc_den1, pcc_den2 = compute_pcc_components(out, targets)\n",
    "        total_sse += sse.item()\n",
    "        total_ssim = structural_similarity_index_measure(out, targets).item()\n",
    "        total_pcc_num += pcc_num.sum().item()\n",
    "        total_pcc_den1 += pcc_den1.sum().item()\n",
    "        total_pcc_den2 += pcc_den2.sum().item()\n",
    "        inputs, targets = prefetcher.next()\n",
    "    avg_mse = total_sse / pixels\n",
    "    avg_rmse = avg_mse ** 0.5\n",
    "    return (total_loss / count, avg_rmse, 20 * np.log10(1.0 / avg_rmse), total_ssim / count,\n",
    "            (total_pcc_num / (total_pcc_den1 * total_pcc_den2) ** 0.5))"
   ],
   "id": "90e8afa5dad977a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Objective method for k fold cross validation",
   "id": "3ad383cdfdc0d080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial, trainset, scaler, X):\n",
    "    num_cycles = trial.suggest_int('num_cycles', 4, 10)\n",
    "    cycle_length = num_epochs // num_cycles\n",
    "    final_beta = 0.5\n",
    "    gamma = trial.suggest_float('gamma', 0.1, 1.0)\n",
    "    layers = trial.suggest_categorical('layers', [(16,), (16, 22)])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    latent_dim = trial.suggest_categorical('latent_dim', [64, 128, 256, 512])\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_losses, mean_loss = [], 0.0\n",
    "    split_n = 0\n",
    "    prog_bar = tqdm(kf.split(X), desc=\"Splits\", position=0)\n",
    "    for train_idx, val_idx in prog_bar:\n",
    "        split_n += 1\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, sampler=SubsetRandomSampler(train_idx), num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "        valloader = DataLoader(trainset, batch_size=batch_size, sampler=SubsetRandomSampler(val_idx), num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "        criterion1 = nn.MSELoss(reduction='mean').to(device, memory_format=torch.channels_last)\n",
    "        criterion2 = VGGLoss(layers=layers).to(device, memory_format=torch.channels_last)\n",
    "        # prior = compute_ab_prior(trainloader)\n",
    "        # weights = make_rebalancing_weights(prior, alpha=0.5)\n",
    "        # criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').to(device, memory_format=torch.channels_last)\n",
    "        net = Net(latent_dim).to(device, memory_format=torch.channels_last)\n",
    "        optimizer = optim.AdamW(net.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        for epoch in range(50):\n",
    "            cycle_pos = epoch % cycle_length\n",
    "            beta = final_beta * (0.5 * (1 + np.cos(np.pi * (1 - cycle_pos / cycle_length))))\n",
    "            train_loss, train_rmse, train_psnr, train_ssim, train_pcc = fit(net, trainloader, optimizer, scaler, criterion1, criterion2, gamma, beta)\n",
    "            val_loss, val_rmse, val_psnr, val_ssim, val_pcc = predict(net, valloader, criterion1, criterion2, gamma)\n",
    "            val_losses.append(val_loss)\n",
    "            scheduler.step(val_loss)\n",
    "            prog_bar.set_description(f\"Epoch {epoch + 1}, lr={current_lr}, beta={beta:.3f}, Loss={train_loss:.3f}/{val_loss:.3f} | \"\n",
    "                                     f\"Metrics train/val: RMSE={train_rmse:.3f}/{val_rmse:.3f}, PSNR={train_psnr:.3f}/{val_psnr:.3f}, \"\n",
    "                                     f\"SSIM={train_ssim:.3f}/{val_ssim:.3f}, PCC={train_pcc:.3f}/{val_pcc:.3f}\")\n",
    "        del net, optimizer, scheduler\n",
    "        mean_loss = np.mean(val_losses)\n",
    "        trial.report(mean_loss, split_n)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return mean_loss"
   ],
   "id": "2a2eefa1ed92326e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### CAE NN definition\n",
    "\n",
    "out = (in - kernel + 2 * pad) / stride + 1"
   ],
   "id": "d4e41cba395737a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(Net, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_mu_logvar = nn.Conv2d(256, 2 * latent_dim, kernel_size=1)\n",
    "        # self.fc_mu = nn.Linear(256 * 28 * 28, latent_dim) # 28 is the dimension of the feature map\n",
    "        # self.fc_logvar = nn.Linear(256 * 28 * 28, latent_dim)\n",
    "        self.decoder_input = nn.Linear(latent_dim, 256 * SIZE // 8 * SIZE // 8)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (256, SIZE // 8, SIZE // 8)),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16, 2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x) # [B, 256, 28, 28]\n",
    "        pooled = self.pool(encoded) # [B, 256, 1, 1]\n",
    "        mu_logvar = self.fc_mu_logvar(pooled).squeeze(-1).squeeze(-1) # [B, 2 * latent_dim]\n",
    "        mu, logvar = mu_logvar.chunk(2, dim=1)\n",
    "        # mu = self.fc_mu(encoded)\n",
    "        # logvar = self.fc_logvar(encoded)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        decoder_input = self.decoder_input(z)\n",
    "        x = self.decoder(decoder_input)\n",
    "        return x, mu, logvar"
   ],
   "id": "210bbe18343d7bf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "writer = SummaryWriter('../runs')\n",
    "net = Net().eval()\n",
    "# torch.quantization.fuse_modules(net, [\n",
    "#     ['conv3', 'bnorm1'],\n",
    "#     ['conv4', 'bnorm2'],\n",
    "#     ['conv5', 'bnorm3']\n",
    "# ], inplace=True)\n",
    "net = net.to(device, memory_format=torch.channels_last)\n",
    "for m in net.modules():\n",
    "    if isinstance(m, (torch.nn.Conv2d, torch.nn.ConvTranspose2d)):\n",
    "        m.weight = torch.nn.Parameter(m.weight.to(memory_format=torch.channels_last))\n",
    "dummy = torch.zeros(1, 1, SIZE, SIZE).to(device, memory_format=torch.channels_last)\n",
    "writer.add_graph(net, dummy)\n",
    "writer.flush()\n",
    "summary(net, input_data=dummy, col_names=('input_size', 'output_size', 'num_params', 'trainable'))"
   ],
   "id": "52efb2f40d886975",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Run command:\\\n",
    "tensorboard --logdir=runs\\\n",
    "Visible at http://localhost:6006/"
   ],
   "id": "1fcb9650c3e809a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyper parameter tuning",
   "id": "884003ec27deae8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# del dummy\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# X = np.zeros(len(trainset))\n",
    "# torch.cuda.empty_cache()\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "# study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "# study.optimize(lambda trial: objective(trial, trainset, scaler, X), n_trials=5)"
   ],
   "id": "6308b5bea15ed4cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "#\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "#\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ],
   "id": "af4d5023becd2ee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Entire dataset",
   "id": "71ef4a62e3f959ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-3, fused=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "criterion1 = nn.MSELoss(reduction='mean').to(device, memory_format=torch.channels_last)\n",
    "criterion2 = VGGLoss(layers=(16,)).to(device, memory_format=torch.channels_last)\n",
    "# prior = compute_ab_prior(trainloader).to(device)\n",
    "# weights = make_rebalancing_weights(prior, alpha=0.5)\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').to(device, memory_format=torch.channels_last)\n",
    "del dummy # , prior"
   ],
   "id": "5ae494b225aa7fe2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "34533b0af6975c18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Only for testing botttlenecks",
   "id": "b091148759480b72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import torch.autograd.profiler as prof\n",
    "#\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "# with prof.profile(record_shapes=True, use_cuda=True) as p:\n",
    "#     with prof.record_function(\"train_step\"):\n",
    "#         _, *_ = fit(net, trainloader, optimizer, scaler, criterion)\n",
    "# print(p.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ],
   "id": "e5150cd581334432",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib notebook\n",
    "def update_plot():\n",
    "    line1.set_data(range(len(train_losses)), train_losses)\n",
    "    line2.set_data(range(len(val_losses)), val_losses)\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    fig.canvas.draw()"
   ],
   "id": "458963979fa49c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "early_stopping = EarlyStopping()\n",
    "train_losses, train_rmses, train_psnrs, train_ssims, train_pccs = [], [], [], [], []\n",
    "val_losses, val_rmses, val_psnrs, val_ssims, val_pccs = [], [], [], [], []\n",
    "last_checkpoint = None\n",
    "num_epochs = 50\n",
    "num_cycles = 4\n",
    "cycle_length = num_epochs // num_cycles\n",
    "final_beta = 0.5\n",
    "gamma = 0.0\n",
    "prog_bar = tqdm(range(num_epochs), total=num_epochs, desc='Training', position=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot([], [], label='Train Loss')\n",
    "line2, = ax.plot([], [], label='Val Loss')\n",
    "ax.legend()\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in prog_bar:\n",
    "    cycle_pos = epoch % cycle_length\n",
    "    beta = final_beta * (0.5 * (1 + np.cos(np.pi * (1 - cycle_pos / cycle_length))))\n",
    "    train_loss, train_rmse, train_psnr, train_ssim, train_pcc = fit(net, trainloader, optimizer, scaler, criterion1, criterion2, gamma, beta)\n",
    "    train_losses.append(train_loss)\n",
    "    train_rmses.append(train_rmse)\n",
    "    train_psnrs.append(train_psnr)\n",
    "    train_ssims.append(train_ssim)\n",
    "    train_pccs.append(train_pcc)\n",
    "    val_loss, val_rmse, val_psnr, val_ssim, val_pcc = predict(net, valloader, criterion1, criterion2, gamma)\n",
    "    val_losses.append(val_loss)\n",
    "    val_rmses.append(val_rmse)\n",
    "    val_psnrs.append(val_psnr)\n",
    "    val_ssims.append(val_ssim)\n",
    "    val_pccs.append(val_pcc)\n",
    "    #scheduler.step(val_img_acc) TODO: find the correct factor/scheduling method\n",
    "    #early_stopping(val_loss, net)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    prog_bar.set_description(f\"Epoch {epoch + 1}, lr={current_lr}, beta={beta:.3f}, Loss={train_loss:.3f}/{val_loss:.3f} | \"\n",
    "                             f\"Metrics train/val: RMSE={train_rmse:.3f}/{val_rmse:.3f}, PSNR={train_psnr:.3f}/{val_psnr:.3f}, \"\n",
    "                             f\"SSIM={train_ssim:.3f}/{val_ssim:.3f}, PCC={train_pcc:.3f}/{val_pcc:.3f}\")\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    update_plot()\n",
    "    # if early_stopping.early_stop:\n",
    "    #     print(\"Early stopping\")\n",
    "    #     break\n",
    "save_checkpoint(net, 'lastcheck')\n",
    "writer.flush()"
   ],
   "id": "d3f1531e5ebfb847",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "class ModelWithLoss(nn.Module):\n",
    "    def __init__(self, net, loss_fn):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        preds = self.net(x)\n",
    "        return self.loss_fn(preds, y)"
   ],
   "id": "373f1e0e71eab534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate results\n",
    "\n",
    "To use NN:\n",
    "rt = torch.jit.load(\"model_and_loss.pt\")\\\n",
    "rt.eval()\\\n",
    "out = rt(input_tensor, target_tensor)"
   ],
   "id": "5ef496b060c5cef7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.inference_mode()\n",
    "def final_predict(net, valloader):\n",
    "    net.eval()\n",
    "    ins, preds, truths = [], [], []\n",
    "    prefetcher = CUDAPrefetcher(valloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    prog_bar = tqdm(total=len(valloader), desc='Final Predicting', leave=False)\n",
    "    while inputs is not None:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out, *_ = net(inputs)\n",
    "            out = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "        ins.append(inputs.cpu())\n",
    "        preds.append(out.cpu())\n",
    "        truths.append(targets.cpu())\n",
    "        # ab_pred_soft = torch.einsum('bchw,cd->bdhw', torch.softmax(out.float(), dim=1), cluster_centers)\n",
    "        # preds_soft.append(ab_pred_soft.cpu())\n",
    "        # ab_pred_hard = cluster_centers[out.argmax(1)].permute(0, 3, 1, 2)\n",
    "        # preds_hard.append(ab_pred_hard.cpu())\n",
    "        # truths.append((cluster_centers[targets] + 128).permute(0, 3, 1, 2).cpu())\n",
    "        inputs, targets = prefetcher.next()\n",
    "        prog_bar.update(1)\n",
    "    prog_bar.close()\n",
    "    return ins, preds, truths"
   ],
   "id": "da7b78ab4114faa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "2ad18a041ec04170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# net.load_state_dict(torch.load('../models/checkpoint.pth'))\n",
    "ins, preds, truths = final_predict(net, testloader)\n",
    "# net_script = ModelWithLoss(net, nn.MSELoss(reduction='mean'))\n",
    "# # net_script = ModelWithLoss(net, nn.CrossEntropyLoss(weight=weights, reduction='mean'))\n",
    "# net_script = torch.jit.script(net_script)\n",
    "# net_script.save('../models/model_and_loss.pt')"
   ],
   "id": "474e9b89f3c6b42f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def lab_to_rgb(L, ab):\n",
    "#     L = (L * 100.0).squeeze(0).detach().cpu().numpy() # rescale to [0..100]\n",
    "#     a = ab[0].detach().cpu().numpy() # already in [-128..127]\n",
    "#     b = ab[1].detach().cpu().numpy()\n",
    "#     lab = np.stack([L, a, b], axis=2).astype(np.float32)\n",
    "#     rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "#     return rgb\n",
    "\n",
    "ins = (torch.cat(ins, 0) * L_std.reshape(1, -1, 1, 1) + L_mean.reshape(1, -1, 1, 1)) * 100.0 # unstandardize and rescale to [0..100]\n",
    "# preds_soft = torch.cat(preds_soft, dim=0)\n",
    "# preds_hard = torch.cat(preds_hard, dim=0)\n",
    "# truths = torch.cat(truths, dim=0)\n",
    "\n",
    "preds_rgb = (torch.cat([ins, torch.cat(preds, 0)], 1)\n",
    "             .permute(0, 2, 3, 1).detach().cpu().numpy()) # (N, H, W, 3)\n",
    "preds_rgb = [cv2.cvtColor(img, cv2.COLOR_LAB2RGB) for img in preds_rgb]\n",
    "# preds_rgb_soft = [lab_to_rgb(torch.cat([L, ab], dim=0)) for L, ab in zip(ins, preds_soft)]\n",
    "# preds_rgb_hard = [lab_to_rgb(torch.cat([L, ab], dim=0)) for L, ab in zip(ins, preds_hard)]\n",
    "truths_rgb = (torch.cat([ins, torch.cat(truths, 0)], 1)\n",
    "             .permute(0, 2, 3, 1).detach().cpu().numpy()) # (N, H, W, 3)\n",
    "truths_rgb = [cv2.cvtColor(img, cv2.COLOR_LAB2RGB) for img in truths_rgb]\n",
    "ins = ins.permute(0, 2, 3, 1).detach().cpu().numpy() # (N, H, W, 1)"
   ],
   "id": "9386f5b9a7afc9f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "a377408f2899ebaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(val_losses, label='Val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_rmses, label='Train RMSE')\n",
    "plt.plot(val_rmses, label='Val RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_psnrs, label='Train PSNR')\n",
    "plt.plot(val_psnrs, label='Val PSNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_ssims, label='Train SSIM')\n",
    "plt.plot(val_ssims, label='Val SSIM')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('SSIM')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_pccs, label='Train PCC')\n",
    "plt.plot(val_pccs, label='Val PCC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PCC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(train_pix_accs, label='Train pixel accuracy')\n",
    "# plt.plot(val_pix_accs, label='Val pixel accuracy')\n",
    "# plt.axhline(y=test_pix_acc, color='g', linestyle='--')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "#\n",
    "# plt.figure()\n",
    "# plt.plot(train_img_accs, label='Train per image accuracy')\n",
    "# plt.plot(val_img_accs, label='Test per image accuracy')\n",
    "# plt.axhline(y=test_img_acc, color='g', linestyle='--')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "#\n",
    "# plt.figure()\n",
    "# plt.plot(train_losses, label='Train loss')\n",
    "# plt.plot(val_losses, label='Val loss')\n",
    "# plt.axhline(y=test_loss, color='g', linestyle='--')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.ylim(bottom=0)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "id": "c95813c83890212e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _ in range(5):\n",
    "    idx = np.random.randint(0, len(ins))\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Gray', fontsize=20)\n",
    "    plt.imshow(ins[idx] , cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Predicted', fontsize=20)\n",
    "    plt.imshow(preds_rgb[idx])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Groundtruth', fontsize=20)\n",
    "    plt.imshow(truths_rgb[idx])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# for _ in range(5):\n",
    "#     idx = np.random.randint(0, len(ins))\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.subplot(1, 4, 1)\n",
    "#     plt.title('Gray', fontsize=20)\n",
    "#     plt.imshow(ins[idx].squeeze().cpu().numpy() , cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(1, 4, 2)\n",
    "#     plt.title('Predicted (Soft)', fontsize=20)\n",
    "#     plt.imshow(preds_rgb_soft[idx])\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(1, 4, 3)\n",
    "#     plt.title('Predicted (Hard)', fontsize=20)\n",
    "#     plt.imshow(preds_rgb_hard[idx])\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(1, 4, 4)\n",
    "#     plt.title('Groundtruth', fontsize=20)\n",
    "#     plt.imshow(truths_rgb[idx])\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ],
   "id": "7461edeb4ce4843e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6247055d60c41eb4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
