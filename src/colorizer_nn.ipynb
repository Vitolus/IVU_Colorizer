{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import packages and device selection",
   "id": "b313fc0badf68a12"
  },
  {
   "cell_type": "code",
   "id": "f0ef308ece9649ce",
   "metadata": {},
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import lmdb\n",
    "import pickle\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SIZE = 224\n",
    "seed = 42\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed) # if using CPU\n",
    "torch.cuda.manual_seed(seed) # if using single-GPU\n",
    "torch.cuda.manual_seed_all(seed) # if using multi-GPU\n",
    "torch.backends.cudnn.deterministic = True # deterministic mode\n",
    "torch.backends.cudnn.benchmark = False # disable auto-tuner to find the best algorithm to use for your hardware\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow TensorFloat-32 on matmul operations\n",
    "torch.backends.cudnn.allow_tf32  = True # allow TensorFloat-32 on convolution operations\n",
    "torch.autograd.set_detect_anomaly(True)"
   ],
   "id": "2e23ac1ba4189527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Using device: \", device)",
   "id": "59ca34fe3c6ae5d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Loading and Preprocessing",
   "id": "fbfc50c6b8689727"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### This is used only to visualize some samples from the dataset",
   "id": "6c78250abb31e2a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sort_files(folder):\n",
    "    convert_func = lambda x: int(x) if x.isdigit() else x.lower()\n",
    "    key_func = lambda x: [convert_func(c) for c in re.split('([0-9]+)', x)]\n",
    "    return sorted(folder, key=key_func)\n",
    "\n",
    "input_L = []\n",
    "target_ab = []\n",
    "path = '../data/color'\n",
    "folder = os.listdir(path)\n",
    "folder = sort_files(folder)\n",
    "for file in tqdm(folder, desc='Loading color images'):\n",
    "    img = cv2.imread(os.path.join(path, file), 1)\n",
    "    img = img.astype(np.float32) / 255.0 # [0, 1]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    L = img[:, :, 0:1] # (H, W, 1) [0, 100]\n",
    "    ab = img[:, :, 1:3] # (H, W, 2) [-128, 127]\n",
    "    input_L.append(L)\n",
    "    target_ab.append(ab)\n",
    "input_L = np.array(input_L) # (N, H, W, 1)\n",
    "target_ab = np.array(target_ab) # (N, H, W, 2"
   ],
   "id": "71ceb81e212e2ca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(input_L.shape, target_ab.shape)",
   "id": "3f03936b33e6388b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Display some samples",
   "id": "e01565f8500bee4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _ in range(5):\n",
    "    idx = np.random.randint(0, len(input_L) - 1)\n",
    "    color_img = np.concatenate([input_L[idx] / 100 * 255, target_ab[idx] + 128], axis=2).clip(0, 255).astype(np.uint8)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('RGB Color Image', fontsize=20)\n",
    "    plt.imshow(np.clip(cv2.cvtColor(color_img, cv2.COLOR_LAB2RGB), 0, 255))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Lab Color Image', fontsize=20)\n",
    "    plt.imshow(color_img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Grayscale Image ', fontsize=20)\n",
    "    plt.imshow((input_L[idx] / 100 * 255).astype(np.uint8).squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "id": "8c4b97681d3cd431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Split into training and test data",
   "id": "e78f0f02e2584c76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can use the entire dataset, instead of the file path, as it is small enough to fit in memory",
   "id": "5d271a4d5931e1a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_L = (torch.from_numpy(input_L) / 100.0).permute(0, 3, 1, 2) # (N, 1, H, W) [0, 1]\n",
    "target_ab = torch.from_numpy(target_ab).permute(0, 3, 1, 2) # (N, 2, H, W) [-128, 127]\n",
    "L_train, L_test, ab_train, ab_test = train_test_split(input_L, target_ab, test_size=0.2, random_state=seed)\n",
    "L_val, L_test, ab_val, ab_test = train_test_split(L_test, ab_test, test_size=0.2, random_state=seed)"
   ],
   "id": "dc9ee95b401f03a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(L_train.shape, ab_train.shape)\n",
    "print(L_val.shape, ab_val.shape)\n",
    "print(L_test.shape, ab_test.shape)"
   ],
   "id": "852c84cd362149e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "L_mean = torch.mean(L_train, dim=[0, 2, 3])\n",
    "L_std = torch.std(L_train, dim=[0, 2, 3])"
   ],
   "id": "3cb7f69c462b8201",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(L_mean, L_std)",
   "id": "1e316003a8a3d88a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, L_data, ab_data, L_transform=None):\n",
    "        self.L_data = L_transform(L_data) if L_transform else L_data\n",
    "        self.ab_data = ab_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.L_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.L_data[idx], self.ab_data[idx]\n",
    "\n",
    "class DatasetWithFeatures(torch.utils.data.Dataset):\n",
    "    def __init__(self, og_dataset, lmdb_path):\n",
    "        self.og_dataset = og_dataset\n",
    "        self.lmdb_path = lmdb_path\n",
    "        self.env = None\n",
    "        self.txn = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.og_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.env is None:\n",
    "            self.env = lmdb.open(self.lmdb_path, readonly=True, lock=False, readahead=False)\n",
    "            self.txn = self.env.begin()\n",
    "        L, ab_target = self.og_dataset[idx]\n",
    "        feature_serialized = self.txn.get(f\"{idx}\".encode())\n",
    "        metadata_len = int.from_bytes(feature_serialized[:4], 'little')\n",
    "        metadata = pickle.loads(feature_serialized[4:4 + metadata_len])\n",
    "        shapes = metadata[\"shapes\"]\n",
    "        dtypes = metadata[\"dtypes\"]\n",
    "        data_bytes = feature_serialized[4 + metadata_len:]\n",
    "        target_features = []\n",
    "        current_offset = 0\n",
    "        for shape, dtype in zip(shapes, dtypes):\n",
    "            num_bytes = np.prod(shape) * np.dtype(dtype).itemsize\n",
    "            arr = np.frombuffer(data_bytes, dtype=dtype, count=np.prod(shape), offset=current_offset).reshape(shape)\n",
    "            target_features.append(arr)\n",
    "            current_offset +=num_bytes\n",
    "            # without copy() it is read-only\n",
    "        return L, ab_target, [torch.from_numpy(arr.copy()) for arr in target_features]\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.env is not None:\n",
    "            self.env.close()\n",
    "            self.env = None"
   ],
   "id": "d8b78562cbcec18f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CUDAPrefetcher:\n",
    "    def __init__(self, loader):\n",
    "        self.loader = iter(loader)\n",
    "        self.stream = None\n",
    "        if torch.cuda.is_available():\n",
    "            self.stream = torch.cuda.Stream()\n",
    "        self.next_L = None\n",
    "        self.next_ab = None\n",
    "        self._preload()\n",
    "\n",
    "    def _preload(self):\n",
    "        try:\n",
    "            self.next_L, self.next_ab = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_L = None\n",
    "            self.next_ab = None\n",
    "            return\n",
    "        if self.stream: # Check if a CUDA stream exists\n",
    "            with torch.cuda.stream(self.stream):\n",
    "                self.next_L = self.next_L.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "                self.next_ab = self.next_ab.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "        # If no stream, the data remains on the CPU, which is fine for CPU-only runs\n",
    "\n",
    "    def next(self):\n",
    "        if self.stream: # Wait for the stream only if it exists\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        L, ab = self.next_L, self.next_ab\n",
    "        self._preload()\n",
    "        return L, ab\n",
    "\n",
    "class CUDAPrefetcherWithFeatures:\n",
    "    def __init__(self, loader):\n",
    "        self.loader = iter(loader)\n",
    "        self.stream = None\n",
    "        if torch.cuda.is_available():\n",
    "            self.stream = torch.cuda.Stream()\n",
    "        self.next_L = None\n",
    "        self.next_ab = None\n",
    "        self.next_features = None\n",
    "        self._preload()\n",
    "\n",
    "    def _preload(self):\n",
    "        try:\n",
    "            self.next_L, self.next_ab, self.next_features = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_L = None\n",
    "            self.next_ab = None\n",
    "            self.next_features = None\n",
    "            return\n",
    "        if self.stream: # Check if a CUDA stream exists\n",
    "            with torch.cuda.stream(self.stream):\n",
    "                self.next_L = self.next_L.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "                self.next_ab = self.next_ab.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "                self.next_features = [f.to(device, non_blocking=True) for f in self.next_features]\n",
    "        # If no stream, the data remains on the CPU, which is fine for CPU-only runs\n",
    "\n",
    "    def next(self):\n",
    "        if self.stream: # Wait for the stream only if it exists\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        L, ab, features = self.next_L, self.next_ab, self.next_features\n",
    "        self._preload()\n",
    "        return L, ab, features"
   ],
   "id": "d25b98ac3e54d495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainset = MyDataset(L_train, ab_train, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "valset = MyDataset(L_val, ab_val, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "testset = MyDataset(L_test, ab_test, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "L_mean = L_mean.reshape(1, -1, 1, 1).to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "L_std = L_std.reshape(1, -1, 1, 1).to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "del L_train, ab_train, L_val, ab_val, L_test, ab_test"
   ],
   "id": "ba8dda1b447c7b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training pipeline",
   "id": "5b1cc3045bc3a88a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Early stopping used to stop training if model begins to overfit",
   "id": "6b19cc4864aa482e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_checkpoint(model, name='checkpoint'):\n",
    "    torch.save(model.state_dict(), f\"../models/{name}.pth\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.05):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = np.Inf\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, net):\n",
    "        if self.best_score > val_loss:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "            save_checkpoint(net)\n",
    "        elif self.best_score + self.delta < val_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ],
   "id": "9c573fa9f9a004e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check VGG19 architecture to select layers for perceptual loss",
   "id": "e967f16d07a9f8d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features)",
   "id": "9ed18dbc8495e450",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        blocks = []\n",
    "        vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features\n",
    "        for i in range(len(layers)-1):\n",
    "            blocks.append(nn.Sequential(*list(vgg.children())[layers[i]:layers[i+1]]))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        for block in self.blocks:\n",
    "            block.eval()\n",
    "            for p in block.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1))\n",
    "        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1))\n",
    "\n",
    "    def _lab_to_rgb(self, L, ab):\n",
    "        lab = torch.cat([L, ab], dim=1)  # (B,3,H,W)\n",
    "        # convert to XYZ\n",
    "        Y = (lab[:, 0:1, :, :] + 16.0) / 116.0\n",
    "        X = lab[:, 1:2, :, :] / 500.0 + Y\n",
    "        Z = Y - lab[:, 2:3, :, :] / 200.0\n",
    "        # apply f^-1 (piecewise)\n",
    "        eps = 0.008856\n",
    "        Y = torch.where(Y > eps, Y ** 3, (Y - 16.0 / 116.0) / 7.787)\n",
    "        X = torch.where(X > eps, X ** 3, (X - 16.0 / 116.0) / 7.787)\n",
    "        Z = torch.where(Z > eps, Z ** 3, (Z - 16.0 / 116.0) / 7.787)\n",
    "        xyz = torch.cat([X, Y, Z], dim=1)\n",
    "        # Apply D65 whitepoint scaling\n",
    "        xyz = xyz.clone()\n",
    "        xyz[:, 0:1, :, :] = xyz[:, 0:1, :, :] * 0.95047\n",
    "        xyz[:, 2:3, :, :] = xyz[:, 2:3, :, :] * 1.08883\n",
    "        rgb = torch.zeros_like(xyz)\n",
    "        rgb[:, 0:1, :, :] = (3.2404542 * xyz[:, 0:1, :, :] -\n",
    "                             1.5371385 * xyz[:, 1:2, :, :] -\n",
    "                             0.4985314 * xyz[:, 2:3, :, :])\n",
    "        rgb[:, 1:2, :, :] = (-0.9692660 * xyz[:, 0:1, :, :] +\n",
    "                             1.8760108 * xyz[:, 1:2, :, :] +\n",
    "                             0.0415560 * xyz[:, 2:3, :, :])\n",
    "        rgb[:, 2:3, :, :] = (0.0556434 * xyz[:, 0:1, :, :] -\n",
    "                             0.2040259 * xyz[:, 1:2, :, :] +\n",
    "                             1.0572252 * xyz[:, 2:3, :, :])\n",
    "        # gamma correction\n",
    "        # sanitize NaN/inf first (replace with numeric safe values)\n",
    "        rgb_sane = torch.nan_to_num(rgb, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "        # clamp negative values to avoid NaN in pow\n",
    "        rgb_for_pow = torch.clamp(rgb_sane, min=1e-10)\n",
    "        rgb_pow = rgb_for_pow ** (1.0 / 2.4)\n",
    "        # threshold mask (still uses original rgb for linear branch to preserve negatives)\n",
    "        mask = rgb_sane > 0.0031308\n",
    "        rgb = torch.where(mask, 1.055 * rgb_pow - 0.055, 12.92 * rgb_sane)\n",
    "        rgb = torch.clamp(rgb, 0.0, 1.0) # (B, 3, H, W)\n",
    "        return rgb\n",
    "\n",
    "    def forward(self, L, ab_pred, ab_target):\n",
    "        L = L\n",
    "        pred_rgb = (self._lab_to_rgb(L, ab_pred) - self.mean) / self.std\n",
    "        target_rgb = (self._lab_to_rgb(L, ab_target) - self.mean) / self.std\n",
    "        loss = torch.tensor(0.0, device=device)\n",
    "        x = pred_rgb\n",
    "        y = target_rgb\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            y = block(y)\n",
    "            loss += nn.functional.l1_loss(x, y)\n",
    "        return loss\n",
    "\n",
    "class VGGLossWithFeatures(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(VGGLossWithFeatures, self).__init__()\n",
    "        blocks = []\n",
    "        vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features\n",
    "        for i in range(len(layers)-1):\n",
    "            blocks.append(nn.Sequential(*list(vgg.children())[layers[i]:layers[i+1]]))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "        for block in self.blocks:\n",
    "            block.eval()\n",
    "            for p in block.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1))\n",
    "        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1))\n",
    "\n",
    "    def _lab_to_rgb(self, L, ab):\n",
    "        lab = torch.cat([L, ab], dim=1)  # (B,3,H,W)\n",
    "        # convert to XYZ\n",
    "        Y = (lab[:, 0:1, :, :] + 16.0) / 116.0\n",
    "        X = lab[:, 1:2, :, :] / 500.0 + Y\n",
    "        Z = Y - lab[:, 2:3, :, :] / 200.0\n",
    "        # apply f^-1 (piecewise)\n",
    "        eps = 0.008856\n",
    "        Y = torch.where(Y > eps, Y ** 3, (Y - 16.0 / 116.0) / 7.787)\n",
    "        X = torch.where(X > eps, X ** 3, (X - 16.0 / 116.0) / 7.787)\n",
    "        Z = torch.where(Z > eps, Z ** 3, (Z - 16.0 / 116.0) / 7.787)\n",
    "        xyz = torch.cat([X, Y, Z], dim=1)\n",
    "        # Apply D65 whitepoint scaling\n",
    "        xyz = xyz.clone()\n",
    "        xyz[:, 0:1, :, :] = xyz[:, 0:1, :, :] * 0.95047\n",
    "        xyz[:, 2:3, :, :] = xyz[:, 2:3, :, :] * 1.08883\n",
    "        rgb = torch.zeros_like(xyz)\n",
    "        rgb[:, 0:1, :, :] = (3.2404542 * xyz[:, 0:1, :, :] -\n",
    "                             1.5371385 * xyz[:, 1:2, :, :] -\n",
    "                             0.4985314 * xyz[:, 2:3, :, :])\n",
    "        rgb[:, 1:2, :, :] = (-0.9692660 * xyz[:, 0:1, :, :] +\n",
    "                             1.8760108 * xyz[:, 1:2, :, :] +\n",
    "                             0.0415560 * xyz[:, 2:3, :, :])\n",
    "        rgb[:, 2:3, :, :] = (0.0556434 * xyz[:, 0:1, :, :] -\n",
    "                             0.2040259 * xyz[:, 1:2, :, :] +\n",
    "                             1.0572252 * xyz[:, 2:3, :, :])\n",
    "        # gamma correction\n",
    "        # sanitize NaN/inf first (replace with numeric safe values)\n",
    "        rgb_sane = torch.nan_to_num(rgb, nan=0.0, posinf=1e6, neginf=0.0)\n",
    "        # clamp negative values to avoid NaN in pow\n",
    "        rgb_for_pow = torch.clamp(rgb_sane, min=1e-10)\n",
    "        rgb_pow = rgb_for_pow ** (1.0 / 2.4)\n",
    "        # threshold mask (still uses original rgb for linear branch to preserve negatives)\n",
    "        mask = rgb_sane > 0.0031308\n",
    "        rgb = torch.where(mask, 1.055 * rgb_pow - 0.055, 12.92 * rgb_sane)\n",
    "        rgb = torch.clamp(rgb, 0.0, 1.0) # (B, 3, H, W)\n",
    "        return rgb\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, L , ab_target):\n",
    "        self.eval()\n",
    "        L = L\n",
    "        target_rgb = (self._lab_to_rgb(L, ab_target) - self.mean) / self.std\n",
    "        features = []\n",
    "        y = target_rgb\n",
    "        for block in self.blocks:\n",
    "            y = block(y)\n",
    "            features.append(y.detach().cpu())\n",
    "        return features\n",
    "\n",
    "    def forward(self, L, ab_pred, target_features):\n",
    "        L = L\n",
    "        pred_rgb = (self._lab_to_rgb(L, ab_pred) - self.mean) / self.std\n",
    "        loss = torch.tensor(0.0, device=device)\n",
    "        x = pred_rgb\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            y = target_features[i].to(device, non_blocking=True)\n",
    "            loss += nn.functional.l1_loss(x, y)\n",
    "        return loss"
   ],
   "id": "b7cffc7466a1451a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fit(net, trainloader, optimizer, scaler, loss_pixel_fn, loss_vgg_fn, coeff_vgg, coeff_kld):\n",
    "    total_loss, total_sse, pixels, count = torch.tensor(0.0, device=device), torch.tensor(0.0, device=device), 0, 0\n",
    "    net.train()\n",
    "    prefetcher = CUDAPrefetcher(trainloader)\n",
    "    # prefetcher = CUDAPrefetcherWithFeatures(trainloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    # inputs, targets, targets_features = prefetcher.next()\n",
    "    while inputs is not None:\n",
    "        with torch.amp.autocast(device):\n",
    "            out, mu, logvar = net(inputs)\n",
    "            out = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "            inputs = (inputs * L_std + L_mean) * 100.0\n",
    "            loss_rec = loss_pixel_fn(out, targets)\n",
    "            if coeff_vgg > 0.0:\n",
    "                loss_rec += coeff_vgg * loss_vgg_fn(inputs, out, targets)\n",
    "                # loss_rec += coeff_vgg * loss_vgg_fn(inputs, out, targets_features)\n",
    "            loss_kld = -0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim=1).mean()\n",
    "            loss = loss_rec + coeff_kld * loss_kld\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        if not torch.isfinite(loss):\n",
    "            inputs, targets = prefetcher.next()\n",
    "            # inputs, targets, targets_features = prefetcher.next()\n",
    "            continue\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), 2)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        with torch.no_grad():\n",
    "            total_loss += loss_rec.detach()\n",
    "            count += 1\n",
    "            sse = nn.MSELoss(reduction='sum')(out, targets)\n",
    "            total_sse += sse\n",
    "            pixels += targets.numel()\n",
    "        inputs, targets = prefetcher.next()\n",
    "        # inputs, targets, targets_features = prefetcher.next()\n",
    "    mse = total_sse / pixels\n",
    "    rmse = torch.sqrt(mse)\n",
    "    eps = 1e-10\n",
    "    psnr = 10 * torch.log10((255.0 ** 2) / (mse + eps))\n",
    "    return (total_loss / count).item(), rmse.item(), psnr.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(net, valloader, loss_pixel_fn, loss_vgg_fn, coeff_vgg):\n",
    "    total_loss, total_sse, pixels, count = torch.tensor(0.0, device=device), torch.tensor(0.0, device=device), 0, 0\n",
    "    net.eval()\n",
    "    prefetcher = CUDAPrefetcher(valloader)\n",
    "    # prefetcher = CUDAPrefetcherWithFeatures(valloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    # inputs, targets, targets_features = prefetcher.next()\n",
    "    while inputs is not None:\n",
    "        with torch.amp.autocast(device):\n",
    "            out, mu, logvar = net(inputs)\n",
    "            out = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "            inputs = (inputs * L_std + L_mean) * 100.0\n",
    "            loss_rec = loss_pixel_fn(out, targets)\n",
    "            if coeff_vgg > 0.0:\n",
    "                loss_rec += coeff_vgg * loss_vgg_fn(inputs, out, targets)\n",
    "                # loss_rec += coeff_vgg * loss_vgg_fn(inputs, out, targets_features)\n",
    "        if not torch.isfinite(loss_rec):\n",
    "            inputs, targets = prefetcher.next()\n",
    "            # inputs, targets, targets_features = prefetcher.next()\n",
    "            continue\n",
    "        total_loss += loss_rec.detach()\n",
    "        count += 1\n",
    "        sse = nn.MSELoss(reduction='sum')(out, targets)\n",
    "        total_sse += sse\n",
    "        pixels += targets.numel()\n",
    "        inputs, targets = prefetcher.next()\n",
    "        # inputs, targets, targets_features = prefetcher.next()\n",
    "    mse = total_sse / pixels\n",
    "    rmse = torch.sqrt(mse)\n",
    "    eps = 1e-10\n",
    "    psnr = 10 * torch.log10((255.0 ** 2) / (mse + eps))\n",
    "    return (total_loss / count).item(), rmse.item(), psnr.item()"
   ],
   "id": "90e8afa5dad977a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Objective method for k fold cross validation",
   "id": "3ad383cdfdc0d080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial, trainset, scaler, X):\n",
    "    num_cycles = trial.suggest_int('num_cycles', 4, 10)\n",
    "    cycle_length = num_epochs // num_cycles\n",
    "    final_beta = 0.5\n",
    "    gamma = trial.suggest_float('gamma', 0.1, 1.0)\n",
    "    layers = trial.suggest_categorical('layers', [[0, 17], [0, 26], [0, 17, 26]])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    latent_dim = trial.suggest_categorical('latent_dim', [64, 128, 256, 512])\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_losses, mean_loss = [], 0.0\n",
    "    split_n = 0\n",
    "    prog_bar = tqdm(kf.split(X), desc=\"Splits\", position=0)\n",
    "    for train_idx, val_idx in prog_bar:\n",
    "        split_n += 1\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, sampler=SubsetRandomSampler(train_idx), num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "        valloader = DataLoader(trainset, batch_size=batch_size, sampler=SubsetRandomSampler(val_idx), num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "        criterion1 = nn.MSELoss(reduction='mean').to(device)\n",
    "        criterion2 = VGGLoss(layers).to(device)\n",
    "        net = Net(latent_dim).to(device)\n",
    "        optimizer = optim.AdamW(net.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        for epoch in range(50):\n",
    "            cycle_pos = epoch % cycle_length\n",
    "            beta = final_beta * (0.5 * (1 + np.cos(np.pi * (1 - cycle_pos / cycle_length))))\n",
    "            train_loss, train_rmse, train_psnr = fit(net, trainloader, optimizer, scaler, criterion1, criterion2, gamma, beta)\n",
    "            val_loss, val_rmse, val_psnr = predict(net, valloader, criterion1, criterion2, gamma)\n",
    "            val_losses.append(val_loss)\n",
    "            scheduler.step(val_loss)\n",
    "            prog_bar.set_description(f\"Epoch {epoch + 1}, lr={current_lr}, beta={beta:.3f}, Loss={train_loss:.3f}/{val_loss:.3f} | \"\n",
    "                                     f\"Metrics train/val: RMSE={train_rmse:.3f}/{val_rmse:.3f}, PSNR={train_psnr:.3f}/{val_psnr:.3f}\")\n",
    "        del net, optimizer, scheduler\n",
    "        mean_loss = np.mean(val_losses)\n",
    "        trial.report(mean_loss, split_n)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return mean_loss"
   ],
   "id": "2a2eefa1ed92326e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### CAE NN definition\n",
    "\n",
    "out = (in - kernel + 2 * pad) / stride + 1"
   ],
   "id": "d4e41cba395737a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(Net, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_mu_logvar = nn.Conv2d(256, 2 * latent_dim, kernel_size=1)\n",
    "        self.decoder_input = nn.Linear(latent_dim, 256 * SIZE // 8 * SIZE // 8)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (256, SIZE // 8, SIZE // 8)),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16, 2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x) # [B, 256, 28, 28]\n",
    "        pooled = self.pool(encoded) # [B, 256, 1, 1]\n",
    "        mu_logvar = self.fc_mu_logvar(pooled).squeeze(-1).squeeze(-1) # [B, 2 * latent_dim]\n",
    "        mu, logvar = mu_logvar.chunk(2, dim=1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        decoder_input = self.decoder_input(z)\n",
    "        x = self.decoder(decoder_input)\n",
    "        return x, mu, logvar"
   ],
   "id": "210bbe18343d7bf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "writer = SummaryWriter('../runs')\n",
    "net = Net(latent_dim=64).eval()\n",
    "# torch.quantization.fuse_modules(net, [\n",
    "#     ['conv3', 'bnorm1'],\n",
    "#     ['conv4', 'bnorm2'],\n",
    "#     ['conv5', 'bnorm3']\n",
    "# ], inplace=True)\n",
    "net = net.to(device, memory_format=torch.channels_last)\n",
    "for m in net.modules():\n",
    "    if isinstance(m, (torch.nn.Conv2d, torch.nn.ConvTranspose2d)):\n",
    "        m.weight = torch.nn.Parameter(m.weight.to(memory_format=torch.channels_last))\n",
    "dummy = torch.zeros(1, 1, SIZE, SIZE).to(device, memory_format=torch.channels_last)\n",
    "writer.add_graph(net, dummy)\n",
    "writer.flush()\n",
    "summary(net, input_data=dummy, col_names=('input_size', 'output_size', 'num_params', 'trainable'))"
   ],
   "id": "52efb2f40d886975",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Run command:\\\n",
    "tensorboard --logdir=runs\\\n",
    "Visible at http://localhost:6006/"
   ],
   "id": "1fcb9650c3e809a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyper parameter tuning",
   "id": "884003ec27deae8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# del dummy\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# X = np.zeros(len(trainset))\n",
    "# torch.cuda.empty_cache()\n",
    "# scaler = torch.amp.GradScaler(device)\n",
    "# study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "# study.optimize(lambda trial: objective(trial, trainset, scaler, X), n_trials=5)"
   ],
   "id": "6308b5bea15ed4cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "#\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "#\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ],
   "id": "af4d5023becd2ee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Entire dataset",
   "id": "71ef4a62e3f959ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "layers = [0, 17, 26]",
   "id": "c2871619f82fa466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Precompute VGG features for the entire dataset and save to disk",
   "id": "4bb153e7408ccfe0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# @torch.no_grad()\n",
    "# def create_features_file(vgg, out_dir, dataset):\n",
    "#     lmdb_path = os.path.join(out_dir, \"features.lmdb\")\n",
    "#     if os.path.exists(lmdb_path):\n",
    "#         shutil.rmtree(lmdb_path)\n",
    "#     env = None\n",
    "#     try:\n",
    "#         env = lmdb.open(lmdb_path, map_size=800000000000) # ~700GB\n",
    "#         dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "#         idx = 0\n",
    "#         BATCHES_PER_TRANSACTION = 15\n",
    "#         txn = env.begin(write=True)  # Start the very first transaction here\n",
    "#         for batch_idx, (L_batch, ab_batch) in enumerate(tqdm(dataloader, desc=\"Extracting features to LMDB\")):\n",
    "#             # Check if it's time to commit and start a new transaction\n",
    "#             if batch_idx > 0 and batch_idx % BATCHES_PER_TRANSACTION == 0:\n",
    "#                 txn.commit()\n",
    "#                 txn = env.begin(write=True)\n",
    "#             L_batch = (L_batch.to(device, memory_format=torch.channels_last,non_blocking=True) * L_std + L_mean) * 100.0\n",
    "#             ab_batch = ab_batch.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "#             feature_batch = vgg.extract_features(L_batch, ab_batch)\n",
    "#             bs = L_batch.size(0)\n",
    "#             for i in range(bs):\n",
    "#                 single_features = [f[i].numpy() for f in feature_batch]\n",
    "#                 metadata = {\n",
    "#                     'shapes': [arr.shape for arr in single_features],\n",
    "#                     'dtypes': [str(arr.dtype) for arr in single_features]\n",
    "#                 }\n",
    "#                 metadata_bytes = pickle.dumps(metadata)\n",
    "#                 data_bytes = b''.join([arr.tobytes() for arr in single_features])\n",
    "#                 metadata_len = len(metadata_bytes)\n",
    "#                 feature_serialized = metadata_len.to_bytes(4, 'little') + metadata_bytes + data_bytes\n",
    "#                 txn.put(f\"{idx}\".encode(), feature_serialized)\n",
    "#                 idx += 1\n",
    "#         # Final commit to ensure all remaining changes are saved\n",
    "#         txn.commit()\n",
    "#     finally:\n",
    "#         if env is not None:\n",
    "#             env.close()"
   ],
   "id": "332ead07e7808b39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Uncomment to recreate the feature maps files",
   "id": "8f05e18f3aff0488"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# vgg_extractor = VGGLossWithFeatures(layers).to(device).eval()\n",
    "# out_dir = '../data/features/train'\n",
    "# os.makedirs(out_dir, exist_ok=True)\n",
    "# create_features_file(vgg_extractor, out_dir, trainset)\n",
    "# out_dir = '../data/features/validation'\n",
    "# os.makedirs(out_dir, exist_ok=True)\n",
    "# create_features_file(vgg_extractor, out_dir, valset)\n",
    "# out_dir = '../data/features/test'\n",
    "# os.makedirs(out_dir, exist_ok=True)\n",
    "# create_features_file(vgg_extractor, out_dir, testset)"
   ],
   "id": "3ac36617856a7efe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# trainset = DatasetWithFeatures(trainset, '../data/features/train/features.lmdb')\n",
    "# valset = DatasetWithFeatures(valset, '../data/features/validation/features.lmdb')\n",
    "# testset = DatasetWithFeatures(testset, '../data/features/test/features.lmdb')"
   ],
   "id": "7e85c766fcf82758",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(len(trainset))\n",
    "print(trainset[0][0].shape)\n",
    "print(trainset[0][1].shape)\n",
    "# print(len(trainset[0][2]))\n",
    "# for i, f in enumerate(trainset[0][2]):\n",
    "#     print(f\"Block {i} shape: {f.shape}\")"
   ],
   "id": "ae7c1578efd45df6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Unit test: graident flow check",
   "id": "ce302e82ee350901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_grad_flow(test_net):\n",
    "    test_net.train()\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    # with shuffle True it takes a bit longer\n",
    "    loader = DataLoader(trainset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    print('prefetcher pre')\n",
    "    prefetcher = CUDAPrefetcher(loader)\n",
    "    # prefetcher = CUDAPrefetcherWithFeatures(loader)\n",
    "    print('prefetcher post')\n",
    "    optimizer = optim.AdamW(test_net.parameters(), lr=1e-4)\n",
    "    criterion1 = nn.L1Loss(reduction='mean').to(device)\n",
    "    criterion2 = VGGLoss([0, 17, 26]).to(device)\n",
    "    # criterion2 = VGGLossWithFeatures([0, 17, 26]).to(device)\n",
    "    num_batches = len(loader)\n",
    "    pbar = tqdm(total=num_batches, desc=\"Prefetching\")\n",
    "    print('prefetcher next pre')\n",
    "    inputs, targets = prefetcher.next()\n",
    "    # inputs, targets, features = prefetcher.next()\n",
    "    print('prefetcher next post')\n",
    "    with torch.amp.autocast(device):\n",
    "        out, mu, logvar = test_net(inputs)\n",
    "        out_rescaled = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "        inputs = (inputs * L_std + L_mean) * 100.0\n",
    "        loss_pix = criterion1(out_rescaled, targets)\n",
    "        print(f\"Pixel loss: {loss_pix.item():.4f}\")\n",
    "        loss_vgg = criterion2(inputs, out_rescaled, targets) * 1.0\n",
    "        # loss_vgg = criterion2(inputs, out_rescaled, features) * 1.0\n",
    "        print(f\"VGG loss: {loss_vgg.item():.4f}\")\n",
    "        loss_kld = -0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim=1).mean() * 0.2\n",
    "        print(f\"KLD loss: {loss_kld.item():.4f}\")\n",
    "        loss = loss_pix + loss_vgg + loss_kld\n",
    "        print(f\"Total loss: {loss.item():.4f}\")\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "    nn.utils.clip_grad_norm_(net.parameters(), 2)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    pbar.update(1)\n",
    "    print('prefetcher next pre')\n",
    "    inputs, targets = prefetcher.next()\n",
    "    # inputs, targets, features = prefetcher.next()\n",
    "    print('prefetcher next post')\n",
    "    net_has_grad = False\n",
    "    for p in test_net.parameters():\n",
    "        if p.grad is not None:\n",
    "            if float(p.grad.abs().sum()) > 0.0:\n",
    "                net_has_grad = True\n",
    "                break\n",
    "    vgg_params_ok = True\n",
    "    for name, p in criterion2.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            print(f\"VGGLoss parameter {name} has requires_grad=True (should be False).\")\n",
    "            vgg_params_ok = False\n",
    "        if p.grad is not None:\n",
    "            # Ideally grads are None for frozen params\n",
    "            print(f\"VGGLoss parameter {name} has non-None grad (should be None).\")\n",
    "            vgg_params_ok = False\n",
    "    print(f\"Net received gradient? {net_has_grad}\")\n",
    "    print(f\"VGGLoss params frozen and no grads? {vgg_params_ok}\")\n",
    "    pbar.close()\n",
    "    return net_has_grad, vgg_params_ok\n",
    "\n",
    "test_net = Net().to(device)\n",
    "ok_net, ok_vgg = test_grad_flow(test_net)\n",
    "assert ok_net and ok_vgg, \"Unit test failed: check gradients or VGGLoss freezing\"\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "1c5124f13d673095",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_fit(test_net):\n",
    "    coeff_vgg = 1.0\n",
    "    coeff_kld = 0.2\n",
    "    total_loss, total_sse, pixels, count = torch.tensor(0.0, device=device), torch.tensor(0.0, device=device), 0, 0\n",
    "    optimizer = optim.AdamW(test_net.parameters(), lr=1e-4)\n",
    "    criterion1 = nn.L1Loss(reduction='mean').to(device)\n",
    "    criterion2 = VGGLoss([0, 17, 26]).to(device)\n",
    "    # criterion2 = VGGLossWithFeatures([0, 17, 26]).to(device)\n",
    "    test_net.train()\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    prefetcher = CUDAPrefetcher(loader)\n",
    "    # prefetcher = CUDAPrefetcherWithFeatures(loader)\n",
    "    num_batches = len(loader)\n",
    "    pbar = tqdm(total=num_batches, desc=\"Prefetching\")\n",
    "    inputs, targets = prefetcher.next()\n",
    "    # inputs, targets, targets_features = prefetcher.next()\n",
    "    while inputs is not None:\n",
    "        with torch.amp.autocast(device):\n",
    "            out, mu, logvar = test_net(inputs)\n",
    "            out_rescaled = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "            inputs = (inputs * L_std + L_mean) * 100.0\n",
    "            loss_rec = criterion1(out_rescaled, targets)\n",
    "            if coeff_vgg > 0.0:\n",
    "                loss_rec += coeff_vgg * criterion2(inputs, out_rescaled, targets)\n",
    "                # loss_rec += coeff_vgg * criterion2(inputs, out_rescaled, targets_features)\n",
    "            loss_kld = -0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim=1).mean()\n",
    "            loss = loss_rec + coeff_kld * loss_kld\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), 2)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        with torch.no_grad():\n",
    "            total_loss += loss_rec.detach()\n",
    "            count += 1\n",
    "            sse = nn.MSELoss(reduction='sum')(out, targets)\n",
    "            total_sse += sse\n",
    "            pixels += targets.numel()\n",
    "        pbar.update(1)\n",
    "        inputs, targets = prefetcher.next()\n",
    "        # inputs, targets, targets_features = prefetcher.next()\n",
    "    pbar.close()\n",
    "    mse = total_sse / pixels\n",
    "    rmse = torch.sqrt(mse)\n",
    "    eps = 1e-10\n",
    "    psnr = 10 * torch.log10((255.0 ** 2) / (mse + eps))\n",
    "    return (total_loss / count).item(), rmse.item(), psnr.item()\n",
    "\n",
    "test_net = Net().to(device)\n",
    "test_loss, test_rmse, test_psnr = test_fit(test_net)\n",
    "print(f\"Total loss: {test_loss:.4f}, Total rmse: {test_rmse:.4f}, Total psnr: {test_psnr:.4f}\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "63ebeeff633f066b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-4, fused=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "criterion1 = nn.L1Loss(reduction='mean').to(device)\n",
    "criterion2 = VGGLoss(layers).to(device)\n",
    "del dummy\n",
    "early_stopping = EarlyStopping()\n",
    "train_losses, train_rmses, train_psnrs, train_pccs = [], [], [], []\n",
    "val_losses, val_rmses, val_psnrs, val_pccs = [], [], [], []\n",
    "last_checkpoint = None\n",
    "num_epochs = 50\n",
    "num_cycles = 4\n",
    "cycle_length = num_epochs // num_cycles\n",
    "final_coeff_kld = 0.5\n",
    "coeff_vgg = 1.0"
   ],
   "id": "5ae494b225aa7fe2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "34533b0af6975c18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib notebook\n",
    "def update_plot():\n",
    "    line1.set_data(range(len(train_losses)), train_losses)\n",
    "    line2.set_data(range(len(val_losses)), val_losses)\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    fig.canvas.draw()"
   ],
   "id": "458963979fa49c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prog_bar = tqdm(range(num_epochs), total=num_epochs, desc='Training', position=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot([], [], label='Train Loss')\n",
    "line2, = ax.plot([], [], label='Val Loss')\n",
    "ax.legend()\n",
    "\n",
    "scaler = torch.amp.GradScaler(device)\n",
    "for epoch in prog_bar:\n",
    "    cycle_pos = epoch % cycle_length\n",
    "    coeff_kld = final_coeff_kld * (0.5 * (1 + np.cos(np.pi * (1 - cycle_pos / cycle_length))))\n",
    "    train_loss, train_rmse, train_psnr = fit(net, trainloader, optimizer, scaler, criterion1, criterion2, coeff_vgg, coeff_kld)\n",
    "    train_losses.append(train_loss)\n",
    "    train_rmses.append(train_rmse)\n",
    "    train_psnrs.append(train_psnr)\n",
    "    val_loss, val_rmse, val_psnr = predict(net, valloader, criterion1, criterion2, coeff_vgg)\n",
    "    val_losses.append(val_loss)\n",
    "    val_rmses.append(val_rmse)\n",
    "    val_psnrs.append(val_psnr)\n",
    "    #scheduler.step(val_img_acc)\n",
    "    #early_stopping(val_loss, net)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    prog_bar.set_description(f\"Epoch {epoch + 1}, lr={current_lr}, coeff_kld={coeff_kld:.3f}, Loss={train_loss:.3f}/{val_loss:.3f} | \"\n",
    "                             f\"Metrics train/val: RMSE={train_rmse:.3f}/{val_rmse:.3f}, PSNR={train_psnr:.3f}/{val_psnr:.3f}\")\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    update_plot()\n",
    "    # if early_stopping.early_stop:\n",
    "    #     print(\"Early stopping\")\n",
    "    #     break\n",
    "save_checkpoint(net, 'lastcheck')\n",
    "writer.flush()"
   ],
   "id": "d3f1531e5ebfb847",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "class ModelWithLoss(nn.Module):\n",
    "    def __init__(self, net, loss_fn):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        preds = self.net(x)\n",
    "        return self.loss_fn(preds, y)"
   ],
   "id": "373f1e0e71eab534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate results\n",
    "\n",
    "To use NN:\n",
    "rt = torch.jit.load(\"model_and_loss.pt\")\\\n",
    "rt.eval()\\\n",
    "out = rt(input_tensor, target_tensor)"
   ],
   "id": "5ef496b060c5cef7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.inference_mode()\n",
    "def final_predict(net, testloader):\n",
    "    net.eval()\n",
    "    ins, preds, truths = [], [], []\n",
    "    prefetcher = CUDAPrefetcher(testloader)\n",
    "    # prefetcher = CUDAPrefetcherWithFeatures(testloader)\n",
    "    inputs, targets, *_ = prefetcher.next()\n",
    "    prog_bar = tqdm(total=len(testloader), desc='Final Predicting')\n",
    "    while inputs is not None:\n",
    "        with torch.amp.autocast(device):\n",
    "            out, *_ = net(inputs)\n",
    "            out = (out + 1.0) / 2.0 * 255.0 - 128.0  # rescale to [-128, 127]\n",
    "        ins.append(inputs)\n",
    "        preds.append(out)\n",
    "        truths.append(targets)\n",
    "        inputs, targets, *_ = prefetcher.next()\n",
    "        prog_bar.update(1)\n",
    "    prog_bar.close()\n",
    "    return ins, preds, truths"
   ],
   "id": "da7b78ab4114faa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "2ad18a041ec04170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# net.load_state_dict(torch.load('../models/checkpoint.pth'))\n",
    "ins, preds, truths = final_predict(net, testloader)\n",
    "# net_script = ModelWithLoss(net, nn.MSELoss(reduction='mean'))\n",
    "# # net_script = ModelWithLoss(net, nn.CrossEntropyLoss(weight=weights, reduction='mean'))\n",
    "# net_script = torch.jit.script(net_script)\n",
    "# net_script.save('../models/model_and_loss.pt')"
   ],
   "id": "474e9b89f3c6b42f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ins = (torch.cat(ins, 0) * L_std + L_mean) * 100.0 # unstandardize and rescale to [0, 100]\n",
    "preds_rgb = (torch.cat([ins, torch.cat(preds, 0)], 1)\n",
    "             .permute(0, 2, 3, 1).detach().cpu().numpy()) # (N, H, W, 3)\n",
    "preds_rgb = [cv2.cvtColor(img, cv2.COLOR_LAB2RGB) for img in preds_rgb]\n",
    "truths_rgb = (torch.cat([ins, torch.cat(truths, 0)], 1)\n",
    "             .permute(0, 2, 3, 1).detach().cpu().numpy()) # (N, H, W, 3)\n",
    "truths_rgb = [cv2.cvtColor(img, cv2.COLOR_LAB2RGB) for img in truths_rgb]\n",
    "ins = ins.permute(0, 2, 3, 1).detach().cpu().numpy() # (N, H, W, 1)"
   ],
   "id": "9386f5b9a7afc9f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "a377408f2899ebaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(val_losses, label='Val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_rmses, label='Train RMSE')\n",
    "plt.plot(val_rmses, label='Val RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_psnrs, label='Train PSNR')\n",
    "plt.plot(val_psnrs, label='Val PSNR')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "c95813c83890212e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _ in range(5):\n",
    "    idx = np.random.randint(0, len(ins))\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Gray', fontsize=20)\n",
    "    plt.imshow(ins[idx] , cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Predicted', fontsize=20)\n",
    "    plt.imshow(preds_rgb[idx])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Groundtruth', fontsize=20)\n",
    "    plt.imshow(truths_rgb[idx])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "id": "7461edeb4ce4843e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6247055d60c41eb4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
