{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import packages and device selection",
   "id": "b313fc0badf68a12"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SIZE = 160\n",
    "seed = 42\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed) # if using CPU\n",
    "torch.cuda.manual_seed(seed) # if using single-GPU\n",
    "torch.cuda.manual_seed_all(seed) # if using multi-GPU\n",
    "torch.backends.cudnn.deterministic = True # deterministic mode\n",
    "torch.backends.cudnn.benchmark = False # disable auto-tuner to find the best algorithm to use for your hardware\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow TensorFloat-32 on matmul operations\n",
    "torch.backends.cudnn.allow_tf32  = True # allow TensorFloat-32 on convolution operations"
   ],
   "id": "2e23ac1ba4189527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Using device: \", device)",
   "id": "59ca34fe3c6ae5d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Loading and Preprocessing",
   "id": "fbfc50c6b8689727"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sort_files(folder):\n",
    "    convert_func = lambda x: int(x) if x.isdigit() else x.lower()\n",
    "    key_func = lambda x: [convert_func(c) for c in re.split('([0-9]+)', x)]\n",
    "    return sorted(folder, key=key_func)\n",
    "\n",
    "input_L = []\n",
    "target_ab = []\n",
    "path = '../data/color'\n",
    "folder = os.listdir(path)\n",
    "folder = sort_files(folder)\n",
    "for file in tqdm(folder, desc='Loading color images'):\n",
    "    img = cv2.imread(os.path.join(path, file), 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    L = img[:, :, 0:1] / 255.0 # (H, W, 1) [0..1]\n",
    "    ab = img[:, :, 1:3] # (H, W, 2) [0..255]\n",
    "    input_L.append(L)\n",
    "    target_ab.append(ab)\n",
    "input_L = np.array(input_L).astype(np.float32) # (N, H, W, 1)\n",
    "target_ab = np.array(target_ab).astype(np.uint8) # (N, H, W, 2)"
   ],
   "id": "71ceb81e212e2ca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(input_L.shape, target_ab.shape)",
   "id": "3f03936b33e6388b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Display some samples",
   "id": "e01565f8500bee4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _ in range(5):\n",
    "    idx = np.random.randint(0, len(input_L) - 1)\n",
    "    color_img = np.concatenate([input_L[idx] * 255, target_ab[idx]], axis=2).astype(np.uint8)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('RGB Color Image', fontsize=20)\n",
    "    plt.imshow(np.clip(cv2.cvtColor(color_img, cv2.COLOR_LAB2RGB), 0, 255))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Lab Color Image', fontsize=20)\n",
    "    plt.imshow(color_img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Grayscale Image ', fontsize=20)\n",
    "    plt.imshow((input_L[idx] * 255).astype(np.uint8).squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "id": "8c4b97681d3cd431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Split into training and test data",
   "id": "e78f0f02e2584c76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_L = np.transpose(input_L, (0, 3, 1, 2)) # (N, 1, H, W)\n",
    "target_ab = np.transpose(target_ab, (0, 3, 1, 2)) # (N, 2, H, W)\n",
    "L_train, L_test, ab_train, ab_test = train_test_split(input_L, target_ab, test_size=0.3, random_state=seed)\n",
    "L_val, L_test, ab_val, ab_test = train_test_split(L_test, ab_test, test_size=0.3, random_state=seed)\n",
    "del input_L, target_ab\n",
    "L_train = torch.tensor(L_train, dtype=torch.float32)\n",
    "ab_train = torch.tensor(ab_train, dtype=torch.uint8)\n",
    "L_val = torch.tensor(L_val, dtype=torch.float32)\n",
    "ab_val = torch.tensor(ab_val, dtype=torch.uint8)\n",
    "L_test = torch.tensor(L_test, dtype=torch.float32)\n",
    "ab_test = torch.tensor(ab_test, dtype=torch.uint8)"
   ],
   "id": "f186b3490baaee72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(L_train.shape, ab_train.shape)\n",
    "print(L_val.shape, ab_val.shape)\n",
    "print(L_test.shape, ab_test.shape)"
   ],
   "id": "720cc390edef796a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "L_mean = L_train.mean(dim=(0, 2, 3))\n",
    "L_std = L_train.std(dim=(0, 2, 3))"
   ],
   "id": "3fc3a89737df7119",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(L_mean, L_std)",
   "id": "5d6ffe3602c4a41b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def unstandardize(tensor, mean, std):\n",
    "    og_shape = tensor.shape\n",
    "    C, H, W = og_shape[-3:]\n",
    "    tensor = (tensor.reshape(-1, C, H, W) * std.reshape(1, C, 1, 1) + mean.reshape(1, C, 1, 1)).clamp(0, 1)  # unnormalize to [0, 1]\n",
    "    return tensor.reshape(og_shape)  # restore original shape\n",
    "\n",
    "def compute_ab_prior(dataloader):\n",
    "    hist = torch.zeros(313)\n",
    "    total = 0\n",
    "    for _, labels in dataloader:\n",
    "        hist += torch.bincount(labels.reshape(-1), minlength=313)  # accumulate histogram\n",
    "        total += labels.numel()\n",
    "        del labels\n",
    "    return hist / total # p(c)\n",
    "\n",
    "def make_rebalancing_weights(priors, alpha=0.5):\n",
    "    C = priors.size(0)\n",
    "    uniform = torch.full_like(priors, 1.0 / C, device=device)\n",
    "    smoothed = (1.0 - alpha) * uniform + alpha * priors\n",
    "    weights = 1.0 / smoothed # inverse of smoothed priors (Cross entropies) [0..inf]\n",
    "    return weights / weights.mean()\n",
    "\n",
    "def lab_to_rgb(x):\n",
    "    lab = x.permute(1, 2, 0)\n",
    "    L = (lab[:, :, 0] * 255).cpu().numpy().astype(np.uint8)\n",
    "    a = (lab[:, :, 1] * 255).cpu().numpy().astype(np.uint8)\n",
    "    b = (lab[:, :, 2] * 255).cpu().numpy().astype(np.uint8)\n",
    "    lab_cv = np.stack([L, a, b], axis=2)\n",
    "    rgb = cv2.cvtColor(lab_cv, cv2.COLOR_LAB2RGB)\n",
    "    return rgb"
   ],
   "id": "a407610ca124fbf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, L_data, ab_data, lut, L_transform=None):\n",
    "        self.L_data = L_transform(L_data) if L_transform else L_data\n",
    "        lut = lut.cpu()\n",
    "        with torch.no_grad():\n",
    "            a = ab_data[:, 0, :, :].long()\n",
    "            b = ab_data[:, 1, :, :].long()\n",
    "            idx = (a * 256 + b).reshape(a.size(0), -1)\n",
    "            labels = lut[idx]\n",
    "            self.labels = labels.reshape_as(a)\n",
    "        del a, b, idx, labels, lut\n",
    "    def __len__(self):\n",
    "        return self.L_data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.L_data[idx], self.labels[idx]"
   ],
   "id": "d8b78562cbcec18f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CUDAPrefetcher:\n",
    "    def __init__(self, loader):\n",
    "        self.loader = iter(loader)\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.next_L = None\n",
    "        self.next_labels = None\n",
    "        self._preload()\n",
    "\n",
    "    def _preload(self):\n",
    "        try:\n",
    "            self.next_L, self.next_labels = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_L = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_L = self.next_L.to(device, memory_format=torch.channels_last, non_blocking=True)\n",
    "            self.next_labels = self.next_labels.to(device, non_blocking=True)\n",
    "\n",
    "    def next(self):\n",
    "        torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        L, labels = self.next_L, self.next_labels\n",
    "        self._preload()\n",
    "        return L, labels"
   ],
   "id": "d25b98ac3e54d495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training pipeline",
   "id": "5b1cc3045bc3a88a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_path = '../data/pts_in_hull.npy'\n",
    "assert os.path.exists(cluster_path), \"Download pts_in_hull.npy and place next to this script\"\n",
    "cluster_centers = torch.from_numpy(np.load(cluster_path)).float() # (313, 2) [-128..127]\n",
    "cc_l2 = (cluster_centers ** 2).sum(dim=1) # (313,)\n",
    "lut_coords  = (((torch.stack(torch.meshgrid(torch.arange(256), torch.arange(256), indexing='xy'), dim=-1).float()) - 128.0)\n",
    "               .reshape(-1, 2)) # (65536, 2) [-128..127]\n",
    "\n",
    "def compute_dist(tensor):\n",
    "    dists = ((tensor ** 2).sum(dim=1, keepdim=True) # (B*H*W, 1)\n",
    "             + cc_l2.reshape(1, -1) # (1, 313)\n",
    "             - 2 * torch.matmul(tensor, cluster_centers.t())) # (B*H*W, 313)\n",
    "    return dists\n",
    "\n",
    "dists = compute_dist(lut_coords)\n",
    "del lut_coords\n",
    "# lut = torch.argmin(dists, dim=1).long() # (65536,) [0..312] LUT for mapping (a, b) to cluster index\n",
    "soft_lut_probs = torch.softmax(-dists, dim=1)  # shape: (65536, 313)\n",
    "lut = torch.argmax(soft_lut_probs, dim=1).long()  # shape: (65536,)\n",
    "del dists"
   ],
   "id": "a3104fa964b7baf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainset = MyDataset(L_train, ab_train, lut, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "valset = MyDataset(L_val, ab_val, lut, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "testset = MyDataset(L_test, ab_test, lut, L_transform=transforms.Normalize(mean=L_mean, std=L_std))\n",
    "del L_train, L_test, ab_train, ab_test"
   ],
   "id": "ba8dda1b447c7b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Early stopping used to stop training if model begins to overfit",
   "id": "6b19cc4864aa482e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_checkpoint(model, name='checkpoint'):\n",
    "    torch.save(model.state_dict(), f\"../models/{name}.pth\")\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.05):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = np.Inf\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, net):\n",
    "        if self.best_score > val_loss:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "            save_checkpoint(net)\n",
    "        elif self.best_score + self.delta < val_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ],
   "id": "9c573fa9f9a004e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fit(net, trainloader, optimizer, scaler, loss_fn, beta=0.5):\n",
    "    net.train()\n",
    "    loss_sum = torch.zeros(1, device=device) # sum of per-pixel losses\n",
    "    pixel_acc = torch.zeros(1, device=device) # total correct pixels\n",
    "    pixel_total = torch.zeros(1, device=device) # total valid pixels\n",
    "    image_acc = torch.zeros(1, device=device) # sum of per-image accuracies\n",
    "    image_count = torch.zeros(1, device=device) # count of images contributing to per-image metric\n",
    "    prefetcher = CUDAPrefetcher(trainloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    while inputs is not None:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out, mu, logvar = net(inputs)\n",
    "            loss_clf = loss_fn(out, targets)\n",
    "            loss_kld = ((-0.5 * torch.mean(1 + logvar - mu ** 2 - logvar.exp())) /\n",
    "                        (inputs.size(0) * inputs.size(2) * inputs.size(3))) # normalize by batch*H*W\n",
    "            loss = loss_clf + beta * loss_kld\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), 3)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        with torch.no_grad():\n",
    "            valid = torch.ones_like(targets, dtype=torch.bool)\n",
    "            # Pixel accuracy\n",
    "            correct = (out.argmax(1) == targets) & valid\n",
    "            pixel_acc += correct.sum()\n",
    "            batch_valid_pixels = valid.sum()\n",
    "            pixel_total += batch_valid_pixels\n",
    "            # Mean per-image accuracy\n",
    "            B = targets.size(0)\n",
    "            correct_per = correct.reshape(B, -1).sum(dim=1)\n",
    "            valid_per = valid.reshape(B, -1).sum(dim=1)\n",
    "            valid_imgs = valid_per > 0\n",
    "            if valid_imgs.any():\n",
    "                image_acc += (correct_per[valid_imgs].float() / valid_per[valid_imgs].float()).sum()\n",
    "                image_count += valid_imgs.sum()\n",
    "            # Loss averaging across epoch\n",
    "            if batch_valid_pixels.item() > 0:\n",
    "                loss_sum += loss.detach() * batch_valid_pixels\n",
    "        # Get the next batch from the prefetcher\n",
    "        inputs, targets = prefetcher.next()\n",
    "    # Safeguards against division by zero\n",
    "    total_valid_pixels = pixel_total.clamp_min(1)\n",
    "    total_valid_images = image_count.clamp_min(1)\n",
    "    return ((loss_sum / total_valid_pixels).item(), (pixel_acc / total_valid_pixels).item(),\n",
    "            (image_acc / total_valid_images).item())\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict(net, valloader, loss_fn, beta=0.5):\n",
    "    net.eval()\n",
    "    loss_sum = torch.zeros(1, device=device)\n",
    "    pixel_acc = torch.zeros(1, device=device)\n",
    "    pixel_total = torch.zeros(1, device=device)\n",
    "    image_acc = torch.zeros(1, device=device)\n",
    "    image_count = torch.zeros(1, device=device)\n",
    "    prefetcher = CUDAPrefetcher(valloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    while inputs is not None:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out, mu, logvar = net(inputs)\n",
    "            loss_clf = loss_fn(out, targets)\n",
    "            loss_kld = ((-0.5 * torch.mean(1 + logvar - mu ** 2 - logvar.exp())) /\n",
    "                        (inputs.size(0) * inputs.size(2) * inputs.size(3)))  # normalize by batch*H*W\n",
    "            loss = loss_clf + beta * loss_kld\n",
    "        valid = torch.ones_like(targets, dtype=torch.bool)\n",
    "        # Pixel accuracy\n",
    "        correct = (out.argmax(1) == targets) & valid\n",
    "        pixel_acc += correct.sum()\n",
    "        batch_valid_pixels = valid.sum()\n",
    "        pixel_total += batch_valid_pixels\n",
    "        # Mean per-image accuracy\n",
    "        B = targets.size(0)\n",
    "        correct_per = correct.reshape(B, -1).sum(dim=1)\n",
    "        valid_per = valid.reshape(B, -1).sum(dim=1)\n",
    "        valid_imgs = valid_per > 0\n",
    "        if valid_imgs.any():\n",
    "            image_acc += (correct_per[valid_imgs].float() / valid_per[valid_imgs].float()).sum()\n",
    "            image_count += valid_imgs.sum()\n",
    "        # Loss averaging across epoch\n",
    "        if batch_valid_pixels.item() > 0:\n",
    "            loss_sum += loss.detach() * batch_valid_pixels\n",
    "        # Get the next batch from the prefetcher\n",
    "        inputs, targets = prefetcher.next()\n",
    "    # Safeguards against division by zero\n",
    "    total_valid_pixels = pixel_total.clamp_min(1)\n",
    "    total_valid_images = image_count.clamp_min(1)\n",
    "    return ((loss_sum / total_valid_pixels).item(), (pixel_acc / total_valid_pixels).item(),\n",
    "            (image_acc / total_valid_images).item())"
   ],
   "id": "90e8afa5dad977a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Objective method for k fold cross validation",
   "id": "3ad383cdfdc0d080"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial, trainset, scaler, X):\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_losses, mean_loss = [], 0.0\n",
    "    split_n = 0\n",
    "    prog_bar = tqdm(kf.split(X), desc=\"Splits\", position=0)\n",
    "    for train_idx, val_idx in prog_bar:\n",
    "        split_n += 1\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, sampler=SubsetRandomSampler(train_idx), num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "        valloader = DataLoader(trainset, batch_size=batch_size, sampler=SubsetRandomSampler(val_idx), num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "        prior = compute_ab_prior(trainloader)\n",
    "        weights = make_rebalancing_weights(prior, alpha=0.5)\n",
    "        criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').to(device, memory_format=torch.channels_last)\n",
    "        net = Net().to(device, memory_format=torch.channels_last)\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        for epoch in range(50):\n",
    "            train_loss, train_pix_acc, train_img_acc = fit(net, trainloader, optimizer, scaler, criterion)\n",
    "            val_loss, val_pix_acc, val_img_acc = predict(net, valloader, criterion)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            scheduler.step(val_loss)\n",
    "            prog_bar.set_description(\n",
    "                f\"Split {split_n} - Epoch {epoch + 1}, lr {lr:.3e}, batch size {batch_size:.3e} |\\n\"\n",
    "                f\"Metrics train/val: Pixel Acc={train_pix_acc:.3e}/{val_pix_acc:.3e}, \"\n",
    "                f\"Img Acc={train_img_acc:.3e}/{val_img_acc:.3e} | Loss: {train_loss:.3e}/{val_loss:.3e}\")\n",
    "        del net, optimizer, scheduler\n",
    "        mean_loss = np.mean(val_losses)\n",
    "        trial.report(mean_loss, split_n)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return mean_loss"
   ],
   "id": "2a2eefa1ed92326e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### CAE NN definition\n",
    "\n",
    "out = (in - kernel + 2 * pad) / stride + 1"
   ],
   "id": "d4e41cba395737a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 128, 4, 2, 1)  # input is L only\n",
    "        self.conv2 = nn.Conv2d(128, 128, 4, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 4, 2, 1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 4, 2, 1)\n",
    "        self.conv5 = nn.Conv2d(512, 512, 4, 2, 1)\n",
    "\n",
    "        self.fc_mu = nn.Linear(512 * 5 * 5, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(512 * 5 * 5, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 512 * 5 * 5)\n",
    "\n",
    "        self.convt1 = nn.ConvTranspose2d(512, 512, 4, 2, 1)\n",
    "        self.convt2 = nn.ConvTranspose2d(1024, 256, 4, 2, 1)\n",
    "        self.convt3 = nn.ConvTranspose2d(512, 128, 4, 2, 1)\n",
    "        self.convt4 = nn.ConvTranspose2d(256, 128, 4, 2, 1)\n",
    "        self.convt5 = nn.ConvTranspose2d(256, 128, 4, 2, 1)\n",
    "\n",
    "        self.bnorm1 = nn.BatchNorm2d(256)\n",
    "        self.bnorm2 = nn.BatchNorm2d(512)\n",
    "        self.bnorm3 = nn.BatchNorm2d(512)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lrelu = nn.LeakyReLU(inplace=True)\n",
    "        self.classifier = nn.Conv2d(128, 313, 1, 1)\n",
    "\n",
    "    def forward(self, x): # x is (B, 1, H, W) => L channel\n",
    "        d1 = self.lrelu(self.conv1(x)) # (B, 128, 80, 80)\n",
    "        d2 = self.lrelu(self.conv2(d1)) # (B, 128, 40, 40)\n",
    "        d3 = self.lrelu(self.bnorm1(self.conv3(d2))) # (B, 256, 20, 20)\n",
    "        d4 = self.lrelu(self.bnorm2(self.conv4(d3))) # (B, 512, 10, 10)\n",
    "        d5 = self.lrelu(self.bnorm3(self.conv5(d4))) # (B, 512, 5, 5)\n",
    "\n",
    "        flat = torch.flatten(d5, start_dim=1) # (B, 512*5*5)\n",
    "        mu = self.fc_mu(flat) # (B, latent_dim)\n",
    "        logvar = self.fc_logvar(flat) # (B, latent_dim)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std # reparameterization trick\n",
    "        decode = self.fc_decode(z) # (B, 512*5*5)\n",
    "        d5 = decode.reshape(-1, 512, 5, 5)\n",
    "\n",
    "        u1 = self.lrelu(self.convt1(d5)) # (B, 512, 10, 10)\n",
    "        u1 = torch.cat([u1, d4], dim=1) # (B, 1024, 10, 10)\n",
    "        u2 = self.lrelu(self.convt2(u1)) # (B, 256, 20, 20)\n",
    "        u2 = torch.cat([u2, d3], dim=1) # (B, 512, 20, 20)\n",
    "        u3 = self.lrelu(self.convt3(u2)) # (B, 128, 40, 40)\n",
    "        u3 = torch.cat([u3, d2], dim=1) # (B, 256, 40, 40)\n",
    "        u4 = self.lrelu(self.convt4(u3)) # (B, 128, 80, 80)\n",
    "        u4 = torch.cat([u4, d1], dim=1) # (B, 256, 80, 80)\n",
    "        u5 = self.lrelu(self.convt5(u4)) # (B, 128, 160, 160)\n",
    "        x = self.classifier(u5) # (B, 313, 160, 160)\n",
    "        return x, mu, logvar"
   ],
   "id": "210bbe18343d7bf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "writer = SummaryWriter('../runs')\n",
    "net = Net().eval()\n",
    "torch.quantization.fuse_modules(net, [\n",
    "    ['conv3', 'bnorm1'],\n",
    "    ['conv4', 'bnorm2'],\n",
    "    ['conv5', 'bnorm3']\n",
    "], inplace=True)\n",
    "net = net.to(device, memory_format=torch.channels_last)\n",
    "for m in net.modules():\n",
    "    if isinstance(m, (torch.nn.Conv2d, torch.nn.ConvTranspose2d)):\n",
    "        m.weight = torch.nn.Parameter(m.weight.to(memory_format=torch.channels_last))\n",
    "dummy = torch.zeros(1, 1, SIZE, SIZE).to(device, memory_format=torch.channels_last)\n",
    "writer.add_graph(net, dummy)\n",
    "writer.flush()\n",
    "summary(net, input_data=dummy, col_names=('input_size', 'output_size', 'num_params', 'trainable'))"
   ],
   "id": "52efb2f40d886975",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Run command:\\\n",
    "tensorboard --logdir=runs\\\n",
    "Visible at http://localhost:6006/"
   ],
   "id": "1fcb9650c3e809a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyper parameter tuning",
   "id": "884003ec27deae8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# del dummy\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# X = np.zeros(len(trainset))\n",
    "# torch.cuda.empty_cache()\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "# study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "# study.optimize(lambda trial: objective(trial, trainset, scaler, X), n_trials=5)"
   ],
   "id": "6308b5bea15ed4cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "#\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "#\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ],
   "id": "af4d5023becd2ee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Entire dataset",
   "id": "71ef4a62e3f959ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-3, fused=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "prior = compute_ab_prior(trainloader).to(device)\n",
    "weights = make_rebalancing_weights(prior, alpha=0.5)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').to(device, memory_format=torch.channels_last)\n",
    "del prior, dummy\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "5ae494b225aa7fe2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "34533b0af6975c18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Only for testing botttlenecks",
   "id": "b091148759480b72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import torch.autograd.profiler as prof\n",
    "#\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "# with prof.profile(record_shapes=True, use_cuda=True) as p:\n",
    "#     with prof.record_function(\"train_step\"):\n",
    "#         _, *_ = fit(net, trainloader, optimizer, scaler, criterion)\n",
    "# print(p.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ],
   "id": "e5150cd581334432",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib notebook\n",
    "def update_plot():\n",
    "    line1.set_data(range(len(train_losses)), train_losses)\n",
    "    line2.set_data(range(len(val_losses)), val_losses)\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    fig.canvas.draw()"
   ],
   "id": "458963979fa49c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "early_stopping = EarlyStopping()\n",
    "train_losses, train_pix_accs, train_img_accs = [], [], []\n",
    "val_losses, val_pix_accs, val_img_accs = [], [], []\n",
    "last_checkpoint = None\n",
    "prog_bar = tqdm(range(50), total=50, desc='Training', position=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot([], [], label='Train Loss')\n",
    "line2, = ax.plot([], [], label='Val Loss')\n",
    "ax.legend()\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in prog_bar:\n",
    "    train_loss, train_pix_acc, train_img_acc = fit(net, trainloader, optimizer, scaler, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    train_pix_accs.append(train_pix_acc)\n",
    "    train_img_accs.append(train_img_acc)\n",
    "    val_loss, val_pix_acc, val_img_acc = predict(net, valloader, criterion)\n",
    "    val_losses.append(val_loss)\n",
    "    val_pix_accs.append(val_pix_acc)\n",
    "    val_img_accs.append(val_img_acc)\n",
    "    #scheduler.step(val_img_acc)\n",
    "    early_stopping(val_loss, net)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    prog_bar.set_description(f\"Epoch {epoch + 1}, lr={current_lr} | Metrics train/val: Pixel Acc={train_pix_acc:.3e}/{val_pix_acc:.3e}, \"\n",
    "                             f\"Image Acc={train_img_acc:.3e}/{val_img_acc:.3e} | Loss: {train_loss:.3e}/{val_loss:.3e}\")\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    update_plot()\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "save_checkpoint(net, 'lastcheck')\n",
    "writer.flush()"
   ],
   "id": "d3f1531e5ebfb847",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelWithLoss(nn.Module):\n",
    "    def __init__(self, net, loss_fn):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        preds = self.net(x)\n",
    "        return self.loss_fn(preds, y)"
   ],
   "id": "373f1e0e71eab534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate results\n",
    "\n",
    "To use NN:\n",
    "rt = torch.jit.load(\"model_and_loss.pt\")\\\n",
    "rt.eval()\\\n",
    "out = rt(input_tensor, target_tensor)"
   ],
   "id": "5ef496b060c5cef7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.inference_mode()\n",
    "def final_predict(net, valloader, loss_fn):\n",
    "    net.eval()\n",
    "    loss_sum = torch.zeros(1, device=device)\n",
    "    pixel_acc = torch.zeros(1, device=device)\n",
    "    pixel_total = torch.zeros(1, device=device)\n",
    "    image_acc = torch.zeros(1, device=device)\n",
    "    image_count = torch.zeros(1, device=device)\n",
    "    ins, preds_soft, preds_hard, truths = [], [], [], []\n",
    "    prefetcher = CUDAPrefetcher(valloader)\n",
    "    inputs, targets = prefetcher.next()\n",
    "    batch_bar = tqdm(total=len(valloader), desc='Final Predicting', leave=False)\n",
    "    while inputs is not None:\n",
    "        ins, preds_soft, preds_hard, truths = [], [], [], []\n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = net(inputs)\n",
    "            loss = loss_fn(out, targets)\n",
    "        valid = torch.ones_like(targets, dtype=torch.bool)\n",
    "        # Pixel accuracy\n",
    "        correct = (out.argmax(1) == targets) & valid\n",
    "        pixel_acc += correct.sum()\n",
    "        batch_valid_pixels = valid.sum()\n",
    "        pixel_total += batch_valid_pixels\n",
    "        # Mean per-image accuracy\n",
    "        B = targets.size(0)\n",
    "        correct_per = correct.reshape(B, -1).sum(dim=1)\n",
    "        valid_per = valid.reshape(B, -1).sum(dim=1)\n",
    "        valid_imgs = valid_per > 0\n",
    "        if valid_imgs.any():\n",
    "            image_acc += (correct_per[valid_imgs].float() / valid_per[valid_imgs].float()).sum()\n",
    "            image_count += valid_imgs.sum()\n",
    "        # Loss averaging across epoch\n",
    "        if batch_valid_pixels.item() > 0:\n",
    "            loss_sum += loss.detach() * batch_valid_pixels\n",
    "        ins.append(inputs.cpu())\n",
    "        ab_pred_soft = torch.einsum('bchw,cd->bdhw', torch.softmax(out.float(), dim=1), cluster_centers)\n",
    "        preds_soft.append(ab_pred_soft.cpu())\n",
    "        ab_pred_hard = cluster_centers[out.argmax(1)].permute(0, 3, 1, 2)\n",
    "        preds_hard.append(ab_pred_hard.cpu())\n",
    "        truths.append((cluster_centers[targets] + 128).permute(0, 3, 1, 2).cpu())\n",
    "        inputs, targets = prefetcher.next()\n",
    "        batch_bar.update(1)\n",
    "    batch_bar.close()\n",
    "    # Safeguards against division by zero\n",
    "    total_valid_pixels = pixel_total.clamp_min(1)\n",
    "    total_valid_images = image_count.clamp_min(1)\n",
    "    return (ins, preds_soft, preds_hard, truths, (loss_sum / total_valid_pixels).item(),\n",
    "            (pixel_acc / total_valid_pixels).item(), (image_acc / total_valid_images).item())"
   ],
   "id": "da7b78ab4114faa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "2ad18a041ec04170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cluster_centers = cluster_centers.to(device)\n",
    "net.load_state_dict(torch.load('../models/checkpoint.pth'))\n",
    "ins, preds_soft, preds_hard, truths, test_loss, test_pix_acc, test_img_acc = final_predict(net, testloader, criterion)\n",
    "net_script = ModelWithLoss(net, nn.CrossEntropyLoss(weight=weights, reduction='mean'))\n",
    "net_script = torch.jit.script(net_script)\n",
    "net_script.save('../models/model_and_loss.pt')"
   ],
   "id": "474e9b89f3c6b42f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "a377408f2899ebaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ins = unstandardize(torch.cat(ins, dim=0), L_mean, L_std)\n",
    "preds_soft = torch.cat(preds_soft, dim=0)\n",
    "preds_hard = torch.cat(preds_hard, dim=0)\n",
    "truths = torch.cat(truths, dim=0)\n",
    "\n",
    "preds_rgb_soft = [lab_to_rgb(torch.cat([L, ab], dim=0)) for L, ab in zip(ins, preds_soft)]\n",
    "preds_rgb_hard = [lab_to_rgb(torch.cat([L, ab], dim=0)) for L, ab in zip(ins, preds_hard)]\n",
    "truths_rgb = [lab_to_rgb(torch.cat([L, ab], dim=0)) for L, ab in zip(ins, truths)]"
   ],
   "id": "9386f5b9a7afc9f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(test_loss, test_pix_acc, test_img_acc)",
   "id": "84e96a7851eeb43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_pix_accs, label='Train pixel accuracy')\n",
    "plt.plot(val_pix_accs, label='Val pixel accuracy')\n",
    "plt.axhline(y=test_pix_acc, color='g', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_img_accs, label='Train per image accuracy')\n",
    "plt.plot(val_img_accs, label='Test per image accuracy')\n",
    "plt.axhline(y=test_img_acc, color='g', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(val_losses, label='Val loss')\n",
    "plt.axhline(y=test_loss, color='g', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "c95813c83890212e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _ in range(5):\n",
    "    idx = np.random.randint(0, len(ins))\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title('Gray', fontsize=20)\n",
    "    plt.imshow(ins[idx].squeeze().cpu().numpy() , cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title('Predicted (Soft)', fontsize=20)\n",
    "    plt.imshow(preds_rgb_soft[idx])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title('Predicted (Hard)', fontsize=20)\n",
    "    plt.imshow(preds_rgb_hard[idx])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title('Groundtruth', fontsize=20)\n",
    "    plt.imshow(truths_rgb[idx])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "id": "7461edeb4ce4843e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "48bb11c5a8056a9a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
